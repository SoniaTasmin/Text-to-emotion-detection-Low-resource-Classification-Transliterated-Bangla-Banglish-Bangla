{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion detection using BiLSTM+CNN+Attention BEmoD's Dataset .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjDKUtvGKmAA",
        "outputId": "9d97077e-1a54-4896-8908-50c3fcc6b0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['cc.bn.300.vec', 'glove.840B.300d.txt', 'crawl-300d-2M.vec', 'class recordings', 'test.xlsx', 'CSE499A Papers', 'trainv1.xlsx', 'cuet_dataset.xlsx', 'cuet_dataset.csv', 'train.csv', 'test.csv']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "myData = '/content/drive/MyDrive/NSU_Courses/CSE/CSE499A';\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(os.listdir(myData))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import datetime\n",
        "import lightgbm as lgb\n",
        "from scipy import stats\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "pd.set_option('max_colwidth',400)"
      ],
      "metadata": {
        "id": "wQqleMqESHUM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(myData+'/train.csv')\n",
        "test = pd.read_csv(myData+'/test.csv')\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bPBDpJrbSHW6",
        "outputId": "7ebb77a7-4e77-46e5-e210-c2f18d233de9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-87539d7c-1227-44c3-93df-3404d2f2c2ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>classes</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>মেডিকেলে এসে ঠিক ফ্যামিলির ফটো ফ্রেম এর মতো মনে হতো নিজেকেখাপছাড়া লাগতোদম বন্ধ হয়ে আসতোঅন্যদের সামনে অপমানিত হতে হতো পদে পদে</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>অনেক দিন পর অন্য রকম অনুভূতি হচ্ছে  কেননা আমার সদ্য পাশ করা শিক্ষার্থীর মত এখন আমিও বেকার বেকার পরিচয় দিয়ে আম্মার কাছ থেকে আজ পঞ্চাশ টাকা ডাকাতি করলাম</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>আগে যতোটা বেশি পছন্দ করতাম দুশ্চরিত্রা মিথিলা মুখার্জি কে এখন তেমনি সবচেয়ে বেশি ঘৃণা করি ওই পতিতা সদ্য হিন্দু হওয়া মিথিলা মুখার্জি কে</td>\n",
              "      <td>disgust</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>মাঝে মাঝে মনে হয় তোমাকে চাওয়াটা অনেক ভুল হয়ত ভুল তবে এই ভুলের মাশুল এইভাবেই কি দিতে হতো জানি না তবে যা জানি তা মানি না</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>এখানে কাওকে কবর দিয়ো না তাহলে তোমাদের পরিবারের আর কেউ বেঁচে থাকবে না ও তোমাদের কাউকে বাঁচতে দিবে না  চলে যাও এখান থেকে নিজে থেকে অভিশাপকে আহ্বান করো না</td>\n",
              "      <td>fear</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87539d7c-1227-44c3-93df-3404d2f2c2ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87539d7c-1227-44c3-93df-3404d2f2c2ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87539d7c-1227-44c3-93df-3404d2f2c2ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  ... labels\n",
              "0           0  ...      1\n",
              "1           1  ...      1\n",
              "2           2  ...      3\n",
              "3           3  ...      1\n",
              "4           4  ...      5\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "-evmIn35SHZb",
        "outputId": "82b167a3-1445-407c-96be-776496aae7bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-09ec718f-aec8-4b05-ba25-a5e0cd91c25e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>classes</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>দুই বছরের ব্যবধানে বগুড়া থেকে বিদেশে পণ্য রপ্তানি সাত গুণ বেড়েছে গত বছর বগুড়া থেকে ভারত ও নেপালে পণ্য রপ্তানি করে আয় হয়েছে ৭ কোটি ২৩ লাখ ৩০ হাজার ৬৩২ মার্কিন ডলার বাংলাদেশি মুদ্রায় রপ্তানি আয়ের পরিমাণ ৬০৭ কোটি ৫৭ লাখ ৭৩ হাজার ৮৮ টাকা</td>\n",
              "      <td>joy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>আওয়ামী লীগ সরকার বাংলাদেশকে অন্ধকার কুয়া থেকে টেনে আলোর পথে এনেছে বলে মন্তব্য করেছেন পরিকল্পনামন্ত্রী এম এ মান্নান তিনি বলেছেন মাথা নুয়ে থাকার দিন শেষ শেখ হাসিনার নেতৃত্বে বাংলাদেশ এখন বিশ্বে মর্যাদার আসনে রয়েছে</td>\n",
              "      <td>joy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>চোখ কচলাতে কচলাতে বেশ রাগান্বীত কন্ঠ বলল ধুরো মরা ঘুমাইয়াও শান্তি নাই এত রাইতে মরতে কই যাইবেন</td>\n",
              "      <td>disgust</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>মেয়েটা অতিরিক্ত আত্মপরিচয় সংকটে ভুগে সাবিলা স্যাবলাই রয়ে গেলো বিউটি উইথআউট ব্রেইন</td>\n",
              "      <td>disgust</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>এবার উন্নয়ন মুলক কাজের কিছু দৃশ্যমান পরিদশন করবেন বাংলাদেশ স্কাউটের ছেলে মেয়েরা বঙ্গবন্ধু শেখ মুজিবুর রহমান শিল্প নগর মিরসরাই চটগ্রামআয়োজনে বেজা অথরিটি মাচ মাসে এটা নিজের চোখে না দেখলে কখনো বিস্বাস করা যাবে না বর্তমান সরকার কি করতে চলেছে এককথায় অসাধারন একটি পরিকল্পনা ধন্যবাদ</td>\n",
              "      <td>joy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09ec718f-aec8-4b05-ba25-a5e0cd91c25e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09ec718f-aec8-4b05-ba25-a5e0cd91c25e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09ec718f-aec8-4b05-ba25-a5e0cd91c25e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  ... labels\n",
              "0           0  ...      0\n",
              "1           1  ...      0\n",
              "2           2  ...      3\n",
              "3           3  ...      3\n",
              "4           4  ...      0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of sentences in train: {}.'.format(train.shape[0]))\n",
        "print('Number of sentences in test: {}.'.format(test.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l-n4Lp8SHaa",
        "outputId": "d31be2c9-dd63-4d09-9c2b-064900c56755"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences in train: 5618.\n",
            "Number of sentences in test: 625.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"classes\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dA5hG4qSHl6",
        "outputId": "099c8a55-3936-4b6a-de84-9f2b8b23ce86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "disgust     1388\n",
              "sadness     1071\n",
              "joy         1028\n",
              "fear         789\n",
              "anger        688\n",
              "surprise     654\n",
              "Name: classes, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test[\"classes\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcSGdhCtSHqC",
        "outputId": "a101ad59-c62b-4a42-bdaf-9bc4d9a16a62"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "disgust     165\n",
              "sadness     119\n",
              "joy         114\n",
              "fear         83\n",
              "surprise     73\n",
              "anger        71\n",
              "Name: classes, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for null values\n",
        "train.info()\n",
        "print()\n",
        "test.info()\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aPnmG9GSHtS",
        "outputId": "5c8eeb7d-33dc-468b-c19e-1ca9b31984f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5618 entries, 0 to 5617\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  5618 non-null   int64 \n",
            " 1   cleaned     5618 non-null   object\n",
            " 2   classes     5618 non-null   object\n",
            " 3   labels      5618 non-null   int64 \n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 175.7+ KB\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 625 entries, 0 to 624\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  625 non-null    int64 \n",
            " 1   cleaned     625 non-null    object\n",
            " 2   classes     625 non-null    object\n",
            " 3   labels      625 non-null    int64 \n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 19.7+ KB\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = TweetTokenizer()"
      ],
      "metadata": {
        "id": "ZjJMP0T6XA7t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\n",
        "full_text = list(train['cleaned'].values) + list(test['cleaned'].values)\n",
        "vectorizer.fit(full_text)\n",
        "train_vectorized = vectorizer.transform(train['cleaned'])\n",
        "test_vectorized = vectorizer.transform(test['cleaned'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CywAfXbyXA-n",
        "outputId": "80f2d111-4c30-4712-c8c0-7205b0cf69cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  \"The parameter 'token_pattern' will not be used\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = train['labels']"
      ],
      "metadata": {
        "id": "da6KqacLXBAx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()\n",
        "ovr = OneVsRestClassifier(logreg)"
      ],
      "metadata": {
        "id": "dUove8gNXBCy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ovr.fit(train_vectorized, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB3k9m7wXBFc",
        "outputId": "00cf9742-3d37-4fb5-e9f2-e1f0b7ccc110"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.18 s, sys: 5.08 s, total: 9.26 s\n",
            "Wall time: 7.09 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression())"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(ovr, train_vectorized, y, scoring='accuracy', n_jobs=-1, cv=3)\n",
        "print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdSzvExsXBGk",
        "outputId": "8924804e-9a95-4068-97d0-fb59a87cce57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation mean accuracy 55.91%, std 0.51.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "svc = LinearSVC(dual=False)\n",
        "scores = cross_val_score(svc, train_vectorized, y, scoring='accuracy', n_jobs=-1, cv=3)\n",
        "print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_32Tzt4XBIU",
        "outputId": "b5e0ed93-e3a7-442b-9a22-9ad49fc47222"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation mean accuracy 59.52%, std 0.97.\n",
            "CPU times: user 34.8 ms, sys: 6.98 ms, total: 41.8 ms\n",
            "Wall time: 1.81 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ovr.fit(train_vectorized, y)\n",
        "svc.fit(train_vectorized, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utkTJRuZXBJ9",
        "outputId": "e63c21a1-77ff-4dd9-8668-beaf4a7b1556"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(dual=False)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU \n",
        "from keras.layers import CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.layers import InputSpec, Layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping"
      ],
      "metadata": {
        "id": "To8kD0neXBMR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk = Tokenizer(lower = True, filters = '')\n",
        "tk.fit_on_texts(full_text)"
      ],
      "metadata": {
        "id": "78bjPZ3vXBN2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenized = tk.texts_to_sequences(train['cleaned'])\n",
        "test_tokenized = tk.texts_to_sequences(test['cleaned'])"
      ],
      "metadata": {
        "id": "nvB-5hn3XBPk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating max length of the vector\n",
        "lens_train = [len(i) for i in train_tokenized]\n",
        "lens_test = [len(i) for i in test_tokenized]\n",
        "lens = lens_train + lens_test\n",
        "\n",
        "max_len = np.max(lens)\n",
        "\n",
        "print('Max len:', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC4CJgLuXBRy",
        "outputId": "58f522e9-12a1-41e5-c6b7-bf31b8964a8a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max len: 215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Zero padding\n",
        "X_train = pad_sequences(train_tokenized, maxlen = max_len)\n",
        "X_test = pad_sequences(test_tokenized, maxlen = max_len)\n",
        "X_test = pad_sequences(test_tokenized, maxlen = max_len)"
      ],
      "metadata": {
        "id": "LimslxhcXBVD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_path = myData+\"/crawl-300d-2M.vec\""
      ],
      "metadata": {
        "id": "H9m30CWsXBWJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 300\n",
        "max_features = 30000"
      ],
      "metadata": {
        "id": "Sqqp9lJ-XBYL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "word_index = tk.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "RnAWimOqeX9z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "y_ohe = ohe.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "3Z6xp0zseYBv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 1\n",
        "def build_model1(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, \n",
        "                 dense_units=128, dr=0.0,conv_size=32):\n",
        "    file_path = \"model_1.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                  save_best_only = True, mode = \"min\")\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "    \n",
        "    inp = Input(shape = (max_len,))\n",
        "    x = Embedding(26277, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
        "\n",
        "    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n",
        "    x1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool1_gru = GlobalAveragePooling1D()(x1)\n",
        "    max_pool1_gru = GlobalMaxPooling1D()(x1)\n",
        "    \n",
        "    x3 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool3_gru = GlobalAveragePooling1D()(x3)\n",
        "    max_pool3_gru = GlobalMaxPooling1D()(x3)\n",
        "    \n",
        "    x_lstm = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x1)\n",
        "    x1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
        "    avg_pool1_lstm = GlobalAveragePooling1D()(x1)\n",
        "    max_pool1_lstm = GlobalMaxPooling1D()(x1)\n",
        "    \n",
        "    x3 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
        "    avg_pool3_lstm = GlobalAveragePooling1D()(x3)\n",
        "    max_pool3_lstm = GlobalMaxPooling1D()(x3)\n",
        "    \n",
        "    \n",
        "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool3_gru, max_pool3_gru,\n",
        "                    avg_pool1_lstm, max_pool1_lstm, avg_pool3_lstm, max_pool3_lstm])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
        "    x = Dense(6, activation = \"sigmoid\")(x)\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    history = model.fit(X_train, y_ohe, batch_size = 128, epochs = 20, validation_split=0.1, \n",
        "                        verbose = 1, callbacks = [check_point, early_stop])\n",
        "    model = load_model(file_path)\n",
        "    return model"
      ],
      "metadata": {
        "id": "YME_1UyveYEY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = build_model1(lr = 1e-3, lr_d = 1e-10, units = 64, spatial_dr = 0.3, kernel_size1=3, \n",
        "                      kernel_size2=2, dense_units=32, dr=0.1, conv_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOU3atVVeYGJ",
        "outputId": "1a79a6bf-bbc8-4d0e-a276-14502d7a8fd8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7494 - accuracy: 0.1968\n",
            "Epoch 00001: val_loss improved from inf to 0.64374, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 23s 214ms/step - loss: 0.7494 - accuracy: 0.1968 - val_loss: 0.6437 - val_accuracy: 0.2616\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.2253\n",
            "Epoch 00002: val_loss improved from 0.64374 to 0.53983, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 7s 177ms/step - loss: 0.6078 - accuracy: 0.2253 - val_loss: 0.5398 - val_accuracy: 0.2633\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.2271\n",
            "Epoch 00003: val_loss improved from 0.53983 to 0.47211, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 7s 176ms/step - loss: 0.5377 - accuracy: 0.2271 - val_loss: 0.4721 - val_accuracy: 0.2669\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4916 - accuracy: 0.2320\n",
            "Epoch 00004: val_loss improved from 0.47211 to 0.47130, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 7s 178ms/step - loss: 0.4916 - accuracy: 0.2320 - val_loss: 0.4713 - val_accuracy: 0.2651\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4724 - accuracy: 0.2397\n",
            "Epoch 00005: val_loss improved from 0.47130 to 0.46760, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 7s 177ms/step - loss: 0.4724 - accuracy: 0.2397 - val_loss: 0.4676 - val_accuracy: 0.2598\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.2508\n",
            "Epoch 00006: val_loss improved from 0.46760 to 0.44815, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 7s 177ms/step - loss: 0.4605 - accuracy: 0.2508 - val_loss: 0.4482 - val_accuracy: 0.2722\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4570 - accuracy: 0.2557\n",
            "Epoch 00007: val_loss improved from 0.44815 to 0.43952, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 7s 175ms/step - loss: 0.4570 - accuracy: 0.2557 - val_loss: 0.4395 - val_accuracy: 0.2883\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4494 - accuracy: 0.2723\n",
            "Epoch 00008: val_loss did not improve from 0.43952\n",
            "40/40 [==============================] - 7s 172ms/step - loss: 0.4494 - accuracy: 0.2723 - val_loss: 0.4427 - val_accuracy: 0.2687\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4466 - accuracy: 0.2809\n",
            "Epoch 00009: val_loss did not improve from 0.43952\n",
            "40/40 [==============================] - 7s 171ms/step - loss: 0.4466 - accuracy: 0.2809 - val_loss: 0.4470 - val_accuracy: 0.2740\n",
            "Epoch 10/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.2747\n",
            "Epoch 00010: val_loss improved from 0.43952 to 0.43790, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 7s 177ms/step - loss: 0.4447 - accuracy: 0.2747 - val_loss: 0.4379 - val_accuracy: 0.2829\n",
            "Epoch 11/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4405 - accuracy: 0.2959\n",
            "Epoch 00011: val_loss did not improve from 0.43790\n",
            "40/40 [==============================] - 7s 171ms/step - loss: 0.4405 - accuracy: 0.2959 - val_loss: 0.4465 - val_accuracy: 0.2598\n",
            "Epoch 12/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.2994\n",
            "Epoch 00012: val_loss did not improve from 0.43790\n",
            "40/40 [==============================] - 7s 172ms/step - loss: 0.4373 - accuracy: 0.2994 - val_loss: 0.4515 - val_accuracy: 0.2331\n",
            "Epoch 13/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.2965\n",
            "Epoch 00013: val_loss improved from 0.43790 to 0.43474, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 7s 177ms/step - loss: 0.4366 - accuracy: 0.2965 - val_loss: 0.4347 - val_accuracy: 0.2811\n",
            "Epoch 14/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.3018\n",
            "Epoch 00014: val_loss did not improve from 0.43474\n",
            "40/40 [==============================] - 7s 172ms/step - loss: 0.4348 - accuracy: 0.3018 - val_loss: 0.4683 - val_accuracy: 0.2135\n",
            "Epoch 15/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4322 - accuracy: 0.3135\n",
            "Epoch 00015: val_loss did not improve from 0.43474\n",
            "40/40 [==============================] - 7s 173ms/step - loss: 0.4322 - accuracy: 0.3135 - val_loss: 0.4490 - val_accuracy: 0.2402\n",
            "Epoch 16/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.3026\n",
            "Epoch 00016: val_loss did not improve from 0.43474\n",
            "40/40 [==============================] - 7s 171ms/step - loss: 0.4316 - accuracy: 0.3026 - val_loss: 0.4450 - val_accuracy: 0.3078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = build_model1(lr = 1e-3, lr_d = 1e-10, units = 128, \n",
        "                      spatial_dr = 0.5, kernel_size1=3, kernel_size2=3, dense_units=64, dr=0.2, conv_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atb6GZpTeYII",
        "outputId": "65338548-226e-48b8-bc4e-a9414be74b5c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.1865\n",
            "Epoch 00001: val_loss improved from inf to 0.51495, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 18s 276ms/step - loss: 0.6857 - accuracy: 0.1865 - val_loss: 0.5150 - val_accuracy: 0.2242\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.2027\n",
            "Epoch 00002: val_loss improved from 0.51495 to 0.46021, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 10s 247ms/step - loss: 0.5273 - accuracy: 0.2027 - val_loss: 0.4602 - val_accuracy: 0.2633\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.2098\n",
            "Epoch 00003: val_loss improved from 0.46021 to 0.45521, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 10s 254ms/step - loss: 0.4881 - accuracy: 0.2098 - val_loss: 0.4552 - val_accuracy: 0.2598\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.2148\n",
            "Epoch 00004: val_loss improved from 0.45521 to 0.44479, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 10s 247ms/step - loss: 0.4765 - accuracy: 0.2148 - val_loss: 0.4448 - val_accuracy: 0.2687\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.2271\n",
            "Epoch 00005: val_loss did not improve from 0.44479\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.4702 - accuracy: 0.2271 - val_loss: 0.4512 - val_accuracy: 0.2527\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.2385\n",
            "Epoch 00006: val_loss improved from 0.44479 to 0.43941, saving model to model_1.hdf5\n",
            "40/40 [==============================] - 10s 246ms/step - loss: 0.4642 - accuracy: 0.2385 - val_loss: 0.4394 - val_accuracy: 0.2562\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.2545\n",
            "Epoch 00007: val_loss did not improve from 0.43941\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.4580 - accuracy: 0.2545 - val_loss: 0.4443 - val_accuracy: 0.2740\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.2498\n",
            "Epoch 00008: val_loss did not improve from 0.43941\n",
            "40/40 [==============================] - 10s 247ms/step - loss: 0.4557 - accuracy: 0.2498 - val_loss: 0.4440 - val_accuracy: 0.2722\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4542 - accuracy: 0.2544\n",
            "Epoch 00009: val_loss did not improve from 0.43941\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.4542 - accuracy: 0.2544 - val_loss: 0.4427 - val_accuracy: 0.2722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model2(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                  save_best_only = True, mode = \"min\")\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "\n",
        "    inp = Input(shape = (max_len,))\n",
        "    x = Embedding(26277, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
        "\n",
        "    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n",
        "    x_lstm = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x1)\n",
        "    \n",
        "    x_conv1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool1_gru = GlobalAveragePooling1D()(x_conv1)\n",
        "    max_pool1_gru = GlobalMaxPooling1D()(x_conv1)\n",
        "    \n",
        "    x_conv2 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool2_gru = GlobalAveragePooling1D()(x_conv2)\n",
        "    max_pool2_gru = GlobalMaxPooling1D()(x_conv2)\n",
        "    \n",
        "    \n",
        "    x_conv3 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
        "    avg_pool1_lstm = GlobalAveragePooling1D()(x_conv3)\n",
        "    max_pool1_lstm = GlobalMaxPooling1D()(x_conv3)\n",
        "    \n",
        "    x_conv4 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
        "    avg_pool2_lstm = GlobalAveragePooling1D()(x_conv4)\n",
        "    max_pool2_lstm = GlobalMaxPooling1D()(x_conv4)\n",
        "    \n",
        "    \n",
        "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool2_gru, max_pool2_gru,\n",
        "                    avg_pool1_lstm, max_pool1_lstm, avg_pool2_lstm, max_pool2_lstm])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
        "    x = Dense(6, activation = \"sigmoid\")(x)\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    history = model.fit(X_train, y_ohe, batch_size = 128, epochs = 20, validation_split=0.1, \n",
        "                        verbose = 1, callbacks = [check_point, early_stop])\n",
        "    model = load_model(file_path)\n",
        "    return model"
      ],
      "metadata": {
        "id": "O4pItiy_eYLI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = build_model2(lr = 1e-4, lr_d = 0, units = 64, spatial_dr = 0.5, kernel_size1=4, \n",
        "                      kernel_size2=3, dense_units=32, dr=0.1, conv_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuNPLduweYrm",
        "outputId": "d5be003e-6d4a-4036-f3dd-2ddb3cb82b37"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7230 - accuracy: 0.1873\n",
            "Epoch 00001: val_loss improved from inf to 0.68029, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 14s 212ms/step - loss: 0.7230 - accuracy: 0.1873 - val_loss: 0.6803 - val_accuracy: 0.1744\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6831 - accuracy: 0.1812\n",
            "Epoch 00002: val_loss improved from 0.68029 to 0.66347, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 187ms/step - loss: 0.6831 - accuracy: 0.1812 - val_loss: 0.6635 - val_accuracy: 0.1477\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6516 - accuracy: 0.1818\n",
            "Epoch 00003: val_loss improved from 0.66347 to 0.64404, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 187ms/step - loss: 0.6516 - accuracy: 0.1818 - val_loss: 0.6440 - val_accuracy: 0.1459\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6273 - accuracy: 0.1905\n",
            "Epoch 00004: val_loss improved from 0.64404 to 0.62498, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 188ms/step - loss: 0.6273 - accuracy: 0.1905 - val_loss: 0.6250 - val_accuracy: 0.1495\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.1889\n",
            "Epoch 00005: val_loss improved from 0.62498 to 0.60418, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 187ms/step - loss: 0.6078 - accuracy: 0.1889 - val_loss: 0.6042 - val_accuracy: 0.1495\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5917 - accuracy: 0.1869\n",
            "Epoch 00006: val_loss improved from 0.60418 to 0.58616, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 187ms/step - loss: 0.5917 - accuracy: 0.1869 - val_loss: 0.5862 - val_accuracy: 0.1655\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.1875\n",
            "Epoch 00007: val_loss improved from 0.58616 to 0.56805, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 194ms/step - loss: 0.5785 - accuracy: 0.1875 - val_loss: 0.5681 - val_accuracy: 0.1886\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.1867\n",
            "Epoch 00008: val_loss improved from 0.56805 to 0.55501, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 189ms/step - loss: 0.5632 - accuracy: 0.1867 - val_loss: 0.5550 - val_accuracy: 0.1957\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5524 - accuracy: 0.1992\n",
            "Epoch 00009: val_loss improved from 0.55501 to 0.53970, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 186ms/step - loss: 0.5524 - accuracy: 0.1992 - val_loss: 0.5397 - val_accuracy: 0.1993\n",
            "Epoch 10/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5483 - accuracy: 0.1865\n",
            "Epoch 00010: val_loss improved from 0.53970 to 0.52461, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 188ms/step - loss: 0.5483 - accuracy: 0.1865 - val_loss: 0.5246 - val_accuracy: 0.2011\n",
            "Epoch 11/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.1867\n",
            "Epoch 00011: val_loss improved from 0.52461 to 0.51161, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 188ms/step - loss: 0.5386 - accuracy: 0.1867 - val_loss: 0.5116 - val_accuracy: 0.1975\n",
            "Epoch 12/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.1940\n",
            "Epoch 00012: val_loss improved from 0.51161 to 0.50219, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 188ms/step - loss: 0.5281 - accuracy: 0.1940 - val_loss: 0.5022 - val_accuracy: 0.2011\n",
            "Epoch 13/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.2006\n",
            "Epoch 00013: val_loss improved from 0.50219 to 0.49218, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 188ms/step - loss: 0.5202 - accuracy: 0.2006 - val_loss: 0.4922 - val_accuracy: 0.2028\n",
            "Epoch 14/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5179 - accuracy: 0.1990\n",
            "Epoch 00014: val_loss improved from 0.49218 to 0.48881, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 187ms/step - loss: 0.5179 - accuracy: 0.1990 - val_loss: 0.4888 - val_accuracy: 0.1993\n",
            "Epoch 15/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.2023\n",
            "Epoch 00015: val_loss improved from 0.48881 to 0.48166, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 187ms/step - loss: 0.5108 - accuracy: 0.2023 - val_loss: 0.4817 - val_accuracy: 0.2153\n",
            "Epoch 16/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.2083\n",
            "Epoch 00016: val_loss improved from 0.48166 to 0.47647, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 186ms/step - loss: 0.5034 - accuracy: 0.2083 - val_loss: 0.4765 - val_accuracy: 0.2367\n",
            "Epoch 17/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5026 - accuracy: 0.2008\n",
            "Epoch 00017: val_loss improved from 0.47647 to 0.46717, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 188ms/step - loss: 0.5026 - accuracy: 0.2008 - val_loss: 0.4672 - val_accuracy: 0.2509\n",
            "Epoch 18/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.2067\n",
            "Epoch 00018: val_loss improved from 0.46717 to 0.46611, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 186ms/step - loss: 0.4994 - accuracy: 0.2067 - val_loss: 0.4661 - val_accuracy: 0.2456\n",
            "Epoch 19/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.2114\n",
            "Epoch 00019: val_loss improved from 0.46611 to 0.46204, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 188ms/step - loss: 0.4922 - accuracy: 0.2114 - val_loss: 0.4620 - val_accuracy: 0.2509\n",
            "Epoch 20/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4870 - accuracy: 0.2176\n",
            "Epoch 00020: val_loss improved from 0.46204 to 0.45986, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 187ms/step - loss: 0.4870 - accuracy: 0.2176 - val_loss: 0.4599 - val_accuracy: 0.2651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = build_model2(lr = 1e-3, lr_d = 0, units = 64, spatial_dr = 0.5, \n",
        "                      kernel_size1=3, kernel_size2=3, dense_units=64, dr=0.3, conv_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy8EVzkHeYtl",
        "outputId": "6b145ace-498c-4c4c-b2ae-50d13ef63613"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.1861\n",
            "Epoch 00001: val_loss improved from inf to 0.55840, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 13s 205ms/step - loss: 0.6376 - accuracy: 0.1861 - val_loss: 0.5584 - val_accuracy: 0.2456\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.1956\n",
            "Epoch 00002: val_loss improved from 0.55840 to 0.48765, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 185ms/step - loss: 0.5221 - accuracy: 0.1956 - val_loss: 0.4876 - val_accuracy: 0.2562\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4949 - accuracy: 0.2189\n",
            "Epoch 00003: val_loss improved from 0.48765 to 0.45839, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 185ms/step - loss: 0.4949 - accuracy: 0.2189 - val_loss: 0.4584 - val_accuracy: 0.2722\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4835 - accuracy: 0.2300\n",
            "Epoch 00004: val_loss improved from 0.45839 to 0.44635, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 184ms/step - loss: 0.4835 - accuracy: 0.2300 - val_loss: 0.4464 - val_accuracy: 0.2616\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.2253\n",
            "Epoch 00005: val_loss improved from 0.44635 to 0.44407, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 185ms/step - loss: 0.4756 - accuracy: 0.2253 - val_loss: 0.4441 - val_accuracy: 0.2616\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.2411\n",
            "Epoch 00006: val_loss improved from 0.44407 to 0.44200, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 186ms/step - loss: 0.4696 - accuracy: 0.2411 - val_loss: 0.4420 - val_accuracy: 0.2633\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4669 - accuracy: 0.2371\n",
            "Epoch 00007: val_loss improved from 0.44200 to 0.44074, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 185ms/step - loss: 0.4669 - accuracy: 0.2371 - val_loss: 0.4407 - val_accuracy: 0.2740\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.2544\n",
            "Epoch 00008: val_loss improved from 0.44074 to 0.43863, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 184ms/step - loss: 0.4603 - accuracy: 0.2544 - val_loss: 0.4386 - val_accuracy: 0.2740\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4587 - accuracy: 0.2532\n",
            "Epoch 00009: val_loss improved from 0.43863 to 0.43459, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 185ms/step - loss: 0.4587 - accuracy: 0.2532 - val_loss: 0.4346 - val_accuracy: 0.2918\n",
            "Epoch 10/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.2591\n",
            "Epoch 00010: val_loss improved from 0.43459 to 0.43425, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 184ms/step - loss: 0.4554 - accuracy: 0.2591 - val_loss: 0.4342 - val_accuracy: 0.2722\n",
            "Epoch 11/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.2698\n",
            "Epoch 00011: val_loss improved from 0.43425 to 0.43328, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 184ms/step - loss: 0.4508 - accuracy: 0.2698 - val_loss: 0.4333 - val_accuracy: 0.2936\n",
            "Epoch 12/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.2585\n",
            "Epoch 00012: val_loss improved from 0.43328 to 0.43282, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 7s 185ms/step - loss: 0.4508 - accuracy: 0.2585 - val_loss: 0.4328 - val_accuracy: 0.2829\n",
            "Epoch 13/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.2801\n",
            "Epoch 00013: val_loss did not improve from 0.43282\n",
            "40/40 [==============================] - 7s 180ms/step - loss: 0.4471 - accuracy: 0.2801 - val_loss: 0.4344 - val_accuracy: 0.2865\n",
            "Epoch 14/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.2743\n",
            "Epoch 00014: val_loss did not improve from 0.43282\n",
            "40/40 [==============================] - 7s 180ms/step - loss: 0.4454 - accuracy: 0.2743 - val_loss: 0.4361 - val_accuracy: 0.2633\n",
            "Epoch 15/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4441 - accuracy: 0.2729\n",
            "Epoch 00015: val_loss did not improve from 0.43282\n",
            "40/40 [==============================] - 7s 181ms/step - loss: 0.4441 - accuracy: 0.2729 - val_loss: 0.4334 - val_accuracy: 0.2918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = build_model2(lr = 1e-3, lr_d = 1e-7, units = 64, spatial_dr = 0.3, \n",
        "                      kernel_size1=3, kernel_size2=3, dense_units=64, dr=0.4, conv_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qazg_-jfeYv0",
        "outputId": "a8216000-fec9-4a54-ebd4-e491935a9f1d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7412 - accuracy: 0.1729\n",
            "Epoch 00001: val_loss improved from inf to 0.55417, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 14s 217ms/step - loss: 0.7412 - accuracy: 0.1729 - val_loss: 0.5542 - val_accuracy: 0.2349\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.1905\n",
            "Epoch 00002: val_loss improved from 0.55417 to 0.51879, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 192ms/step - loss: 0.5832 - accuracy: 0.1905 - val_loss: 0.5188 - val_accuracy: 0.1904\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.2019\n",
            "Epoch 00003: val_loss improved from 0.51879 to 0.47230, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 191ms/step - loss: 0.5256 - accuracy: 0.2019 - val_loss: 0.4723 - val_accuracy: 0.2242\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4997 - accuracy: 0.2158\n",
            "Epoch 00004: val_loss improved from 0.47230 to 0.45401, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 192ms/step - loss: 0.4997 - accuracy: 0.2158 - val_loss: 0.4540 - val_accuracy: 0.2491\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4878 - accuracy: 0.2379\n",
            "Epoch 00005: val_loss improved from 0.45401 to 0.44669, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 193ms/step - loss: 0.4878 - accuracy: 0.2379 - val_loss: 0.4467 - val_accuracy: 0.2722\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4777 - accuracy: 0.2411\n",
            "Epoch 00006: val_loss improved from 0.44669 to 0.44446, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 193ms/step - loss: 0.4777 - accuracy: 0.2411 - val_loss: 0.4445 - val_accuracy: 0.2633\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.2506\n",
            "Epoch 00007: val_loss improved from 0.44446 to 0.44025, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 199ms/step - loss: 0.4735 - accuracy: 0.2506 - val_loss: 0.4403 - val_accuracy: 0.2687\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.2555\n",
            "Epoch 00008: val_loss did not improve from 0.44025\n",
            "40/40 [==============================] - 7s 186ms/step - loss: 0.4648 - accuracy: 0.2555 - val_loss: 0.4410 - val_accuracy: 0.2651\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4616 - accuracy: 0.2698\n",
            "Epoch 00009: val_loss improved from 0.44025 to 0.43848, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 193ms/step - loss: 0.4616 - accuracy: 0.2698 - val_loss: 0.4385 - val_accuracy: 0.2847\n",
            "Epoch 10/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.2708\n",
            "Epoch 00010: val_loss did not improve from 0.43848\n",
            "40/40 [==============================] - 7s 187ms/step - loss: 0.4583 - accuracy: 0.2708 - val_loss: 0.4450 - val_accuracy: 0.2776\n",
            "Epoch 11/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.2757\n",
            "Epoch 00011: val_loss improved from 0.43848 to 0.43664, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 192ms/step - loss: 0.4547 - accuracy: 0.2757 - val_loss: 0.4366 - val_accuracy: 0.2865\n",
            "Epoch 12/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.2799\n",
            "Epoch 00012: val_loss did not improve from 0.43664\n",
            "40/40 [==============================] - 7s 187ms/step - loss: 0.4527 - accuracy: 0.2799 - val_loss: 0.4372 - val_accuracy: 0.2776\n",
            "Epoch 13/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.2793\n",
            "Epoch 00013: val_loss improved from 0.43664 to 0.43105, saving model to best_model.hdf5\n",
            "40/40 [==============================] - 8s 193ms/step - loss: 0.4493 - accuracy: 0.2793 - val_loss: 0.4311 - val_accuracy: 0.3007\n",
            "Epoch 14/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4464 - accuracy: 0.2858\n",
            "Epoch 00014: val_loss did not improve from 0.43105\n",
            "40/40 [==============================] - 8s 188ms/step - loss: 0.4464 - accuracy: 0.2858 - val_loss: 0.4319 - val_accuracy: 0.3007\n",
            "Epoch 15/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.2937\n",
            "Epoch 00015: val_loss did not improve from 0.43105\n",
            "40/40 [==============================] - 7s 188ms/step - loss: 0.4447 - accuracy: 0.2937 - val_loss: 0.4384 - val_accuracy: 0.2829\n",
            "Epoch 16/20\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.2838\n",
            "Epoch 00016: val_loss did not improve from 0.43105\n",
            "40/40 [==============================] - 8s 188ms/step - loss: 0.4443 - accuracy: 0.2838 - val_loss: 0.4377 - val_accuracy: 0.2883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred1 = model1.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "pred = pred1\n",
        "pred2 = model2.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "pred += pred2\n",
        "pred3 = model3.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "pred += pred3\n",
        "pred4 = model4.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "pred += pred4\n",
        "pred5 = model5.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "pred += pred5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBpFBOxjo8Aa",
        "outputId": "95f3cc3e-c254-496c-b409-f3a811e4eec6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 644ms/step\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff016642950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 1s 882ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(Layer):\n",
        "    \"\"\"\n",
        "    Keras Layer that implements an Attention mechanism for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    :param kwargs:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(Attention())\n",
        "    \"\"\"\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "        eij = K.tanh(eij)\n",
        "        a = K.exp(eij)\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0],  self.features_dim"
      ],
      "metadata": {
        "id": "KRV-r0gfo8Do"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(maxlen, max_features, embed_size, embedding_matrix):\n",
        "    input_words = Input((max_len, ))\n",
        "    x_words = Embedding(26277,\n",
        "                        embed_size,\n",
        "                        weights=[embedding_matrix],\n",
        "                        mask_zero=True,\n",
        "                        trainable=False)(input_words)\n",
        "    x_words = SpatialDropout1D(0.2)(x_words)\n",
        "    x_words = Bidirectional(LSTM(128, return_sequences=True))(x_words)\n",
        "    x_words = Bidirectional(LSTM(128, return_sequences=True))(x_words)\n",
        "    \n",
        "    x = Attention(maxlen)(x_words)\n",
        "    #x = GlobalMaxPooling1D()(x)\n",
        "    #x = GlobalAveragePooling1D()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    pred = Dense(6, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_words, outputs=pred)\n",
        "    return model\n",
        "\n",
        "model = build_model(max_len, max_features, embed_size, embedding_matrix)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlnELRw5o8Eq",
        "outputId": "4467fa0b-52b2-43bc-bb56-5aba2e23953a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 215)]             0         \n",
            "                                                                 \n",
            " embedding_10 (Embedding)    (None, 215, 300)          7883100   \n",
            "                                                                 \n",
            " spatial_dropout1d_8 (Spatia  (None, 215, 300)         0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional_16 (Bidirecti  (None, 215, 256)         439296    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_17 (Bidirecti  (None, 215, 256)         394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " attention_3 (Attention)     (None, 256)               471       \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,733,945\n",
            "Trainable params: 850,845\n",
            "Non-trainable params: 7,883,100\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(maxlen, max_features, embed_size, embedding_matrix):\n",
        "    input_words = Input((max_len, ))\n",
        "    x_words = Embedding(26277,\n",
        "                        embed_size,\n",
        "                        weights=[embedding_matrix],\n",
        "                        mask_zero=True,\n",
        "                        trainable=False)(input_words)\n",
        "    x_words = SpatialDropout1D(0.2)(x_words)\n",
        "    x_words = Bidirectional(LSTM(128, return_sequences=True))(x_words)\n",
        "    x_words = Bidirectional(LSTM(128, return_sequences=True))(x_words)\n",
        "    \n",
        "    x = Attention(maxlen)(x_words)\n",
        "    #x = GlobalMaxPooling1D()(x)\n",
        "    #x = GlobalAveragePooling1D()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    pred = Dense(6, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_words, outputs=pred)\n",
        "    return model\n",
        "\n",
        "model = build_model(max_len, max_features, embed_size, embedding_matrix)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plEH5DUWo8JZ",
        "outputId": "9f798dd3-f32f-44ad-e2f8-d1152f67a587"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 215)]             0         \n",
            "                                                                 \n",
            " embedding_11 (Embedding)    (None, 215, 300)          7883100   \n",
            "                                                                 \n",
            " spatial_dropout1d_9 (Spatia  (None, 215, 300)         0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional_18 (Bidirecti  (None, 215, 256)         439296    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_19 (Bidirecti  (None, 215, 256)         394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " attention_4 (Attention)     (None, 256)               471       \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,733,945\n",
            "Trainable params: 850,845\n",
            "Non-trainable params: 7,883,100\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_file = 'model_CNN_BiLSTM_Attention_BEmoD.h5'\n",
        "#history = model.fit(X_train, y_ohe, batch_size = 128, epochs = 20, validation_split=0.2, \n",
        "                        #verbose = 1, callbacks = [check_point, early_stop])\n",
        "history = model.fit(X_train, y_ohe,\n",
        "                    epochs=20, verbose=1,\n",
        "                    batch_size=512, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lztTPFxEo8OA",
        "outputId": "14b372d4-9ff7-4570-a9eb-10fe79c95dbb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "11/11 [==============================] - 59s 3s/step - loss: 0.5433 - accuracy: 0.1938\n",
            "Epoch 2/20\n",
            "11/11 [==============================] - 40s 4s/step - loss: 0.4682 - accuracy: 0.2141\n",
            "Epoch 3/20\n",
            "11/11 [==============================] - 38s 3s/step - loss: 0.4576 - accuracy: 0.2232\n",
            "Epoch 4/20\n",
            "11/11 [==============================] - 38s 3s/step - loss: 0.4541 - accuracy: 0.2273\n",
            "Epoch 5/20\n",
            "11/11 [==============================] - 37s 3s/step - loss: 0.4510 - accuracy: 0.2348\n",
            "Epoch 6/20\n",
            "11/11 [==============================] - 38s 3s/step - loss: 0.4509 - accuracy: 0.2326\n",
            "Epoch 7/20\n",
            "11/11 [==============================] - 37s 3s/step - loss: 0.4488 - accuracy: 0.2417\n",
            "Epoch 8/20\n",
            "11/11 [==============================] - 36s 3s/step - loss: 0.4466 - accuracy: 0.2471\n",
            "Epoch 9/20\n",
            "11/11 [==============================] - 36s 3s/step - loss: 0.4445 - accuracy: 0.2634\n",
            "Epoch 10/20\n",
            "11/11 [==============================] - 36s 3s/step - loss: 0.4420 - accuracy: 0.2706\n",
            "Epoch 11/20\n",
            "11/11 [==============================] - 37s 3s/step - loss: 0.4404 - accuracy: 0.2736\n",
            "Epoch 12/20\n",
            "11/11 [==============================] - 37s 3s/step - loss: 0.4416 - accuracy: 0.2649\n",
            "Epoch 13/20\n",
            "11/11 [==============================] - 37s 3s/step - loss: 0.4381 - accuracy: 0.2812\n",
            "Epoch 14/20\n",
            "11/11 [==============================] - 37s 3s/step - loss: 0.4388 - accuracy: 0.2793\n",
            "Epoch 15/20\n",
            "11/11 [==============================] - 36s 3s/step - loss: 0.4370 - accuracy: 0.2796\n",
            "Epoch 16/20\n",
            "11/11 [==============================] - 37s 3s/step - loss: 0.4344 - accuracy: 0.2907\n",
            "Epoch 17/20\n",
            "11/11 [==============================] - 36s 3s/step - loss: 0.4339 - accuracy: 0.2946\n",
            "Epoch 18/20\n",
            "11/11 [==============================] - 37s 3s/step - loss: 0.4305 - accuracy: 0.3006\n",
            "Epoch 19/20\n",
            "11/11 [==============================] - 36s 3s/step - loss: 0.4300 - accuracy: 0.3054\n",
            "Epoch 20/20\n",
            "11/11 [==============================] - 38s 3s/step - loss: 0.4282 - accuracy: 0.3168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test, batch_size = 1024, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C7nOhD0xD5X",
        "outputId": "cb87a8e0-691c-43fd-fd1d-b2d38c9ae969"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fef9000be60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 9s 9s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PlotGraph(history):\n",
        "    acc = history.history['accuracy']\n",
        "    #val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    #val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'g', label='Training acc')\n",
        "   # plt.plot(x, val_acc, 'b', label='Validation acc')\n",
        "   # plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'g', label='Training loss')\n",
        "   # plt.plot(x, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "S160Cd8zxD7o"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PlotGraph(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "S3RR18WoxD9c",
        "outputId": "15a6e5b3-7eed-4fd5-9b20-53a34971cad6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAE/CAYAAAC0Fl50AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZyP9f7/8cfLMJYZLbZRllBKsjcpdYoKKZHSQkqShHyVzjkd6rT81DmtJ1pQtNCm7bQQkkqoKCNS9iUVWcbIvoyZef3+mM84H9Mwg5nP9ZmZ5/126+Zzva/3dV3Pz2c0XvOe93W9zd0REREREZH/KRF0ABERERGRaKMiWUREREQkGxXJIiIiIiLZqEgWEREREclGRbKIiIiISDYqkkVEREREslGRLCIiEsXMbLKZ3ZTffYNkZqvNrHUBnNfN7JTQ6+fN7L689D2C63Qzs0+PNOchztvKzNbk93nlyJQMOoCIiEhRY2Y7wjbLAXuB9ND2be7+Rl7P5e6XFkTfos7d++THecysFvAzUMrd00LnfgPI89dQCicVySIiIvnM3eOzXpvZaqCXu3+WvZ+ZlcwqvEQkumi6hYiISIRk/TrdzP5hZuuBV8zseDP72MySzeyP0OvqYcd8aWa9Qq97mNlXZvZkqO/PZnbpEfatbWYzzGy7mX1mZsPN7PWD5M5LxofM7OvQ+T41s0ph+280s1/MLMXM7j3E53O2ma03s5iwtivNbEHodXMzm2VmW8xsnZk9Z2axBznXGDN7OGz776Fjfjezntn6tjezeWa2zcx+M7MHw3bPCP25xcx2mFmLrM827PhzzWyOmW0N/XluXj+bQzGz00PHbzGzhWbWMWzfZWa2KHTOtWb2t1B7pdDXZ4uZbTazmWameu8I6EMTERGJrKpABeAkoDeZ/xa/EtquCewGnjvE8WcDS4FKwOPAS2ZmR9D3TeA7oCLwIHDjIa6Zl4zXAzcDVYBYIKtoqw+MDJ3/xND1qpMDd/8W2AlclO28b4ZepwMDQ++nBXAx0O8QuQllaBfK0waoC2SfD70T6A4cB7QH+ppZp9C+C0J/Hufu8e4+K9u5KwATgWdC7+0pYKKZVcz2Hv702eSSuRQwAfg0dNz/AW+Y2WmhLi+ROXWnPNAA+CLU/ldgDVAZSADuATy368mfqUgWERGJrAzgAXff6+673T3F3f/r7rvcfTvwL6DlIY7/xd1Hu3s6MBY4gcxiKM99zawmcBZwv7unuvtXwPiDXTCPGV9x92Xuvht4B2gSar8a+NjdZ7j7XuC+0GdwMOOArgBmVh64LNSGu89199nunubuq4EXcsiRk2tD+X5y951k/lAQ/v6+dPcf3T3D3ReErpeX80JmUb3c3V8L5RoHLAE6hPU52GdzKOcA8cCjoa/RF8DHhD4bYB9Q38yOcfc/3P37sPYTgJPcfZ+7z3R3FclHQEWyiIhIZCW7+56sDTMrZ2YvhKYjbCPz1/vHhU85yGZ91gt33xV6GX+YfU8ENoe1Afx2sMB5zLg+7PWusEwnhp87VKSmHOxaZI4aX2VmpYGrgO/d/ZdQjlNDUwnWh3L8m8xR5dwckAH4Jdv7O9vMpoWmk2wF+uTxvFnn/iVb2y9AtbDtg302uWZ29/AfKMLP25nMHyB+MbPpZtYi1P4EsAL41MxWmdmgvL0NyU5FsoiISGRlH9X7K3AacLa7H8P/fr1/sCkU+WEdUMHMyoW11ThE/6PJuC783KFrVjxYZ3dfRGYxeCkHTrWAzGkbS4C6oRz3HEkGMqeMhHuTzJH0Gu5+LPB82HlzG4X9ncxpKOFqAmvzkCu389bINp94/3ndfY67X0HmVIwPyRyhxt23u/tf3b0O0BG4y8wuPsosxZKKZBERkWCVJ3OO75bQ/NYHCvqCoZHZJOBBM4sNjUJ2OMQhR5PxPeByM/tL6Ca7IeRef7wJ3EFmMf5uthzbgB1mVg/om8cM7wA9zKx+qEjPnr88mSPre8ysOZnFeZZkMqeH1DnIuScBp5rZ9WZW0syuA+qTOTXiaHxL5qjz3WZWysxakfk1eiv0NetmZse6+z4yP5MMADO73MxOCc0930rmPO5DTW+Rg1CRLCIiEqxhQFlgEzAb+CRC1+1G5s1vKcDDwNtkPs85J0ec0d0XAreTWfiuA/4g88ayQ8maE/yFu28Ka/8bmQXsdmB0KHNeMkwOvYcvyJyK8EW2Lv2AIWa2Hbif0Khs6NhdZM7B/jr0xIhzsp07BbiczNH2FOBu4PJsuQ+bu6eSWRRfSubnPgLo7u5LQl1uBFaHpp30IfPrCZk3Jn4G7ABmASPcfdrRZCmuTHO5RURExMzeBpa4e4GPZIsUBhpJFhERKYbM7CwzO9nMSoQekXYFmXNbRQStuCciIlJcVQXeJ/MmujVAX3efF2wkkeih6RYiIiIiItlouoWIiIiISDYqkkVEREREsom6OcmVKlXyWrVqBR1DROSIzJ07d5O7Vw46RyTp+7aIFFaH+p4ddUVyrVq1SEpKCjqGiMgRMbPsy9MWefq+LSKF1aG+Z+dpuoWZtTOzpWa2Iqc1wM2sj5n9aGbzzewrM6sfam9jZnND++aa2UVH/jZERERERCIj1yLZzGKA4WSu+FIf6JpVBId5090bunsT4HHgqVD7JqCDuzcEbgJey7fkIiIiIiIFJC8jyc2BFe6+KrRE4ltkPnB8P3ffFrYZB3iofZ67/x5qXwiUNbPSRx9bRERERKTg5GVOcjXgt7DtNcDZ2TuZ2e3AXUAskNO0is7A9+5+sHXhD2rfvn2sWbOGPXv2HO6hcpTKlClD9erVKVWqVNBRRERECiXVMcE7knom327cc/fhwHAzux74J5nTKwAwszOAx4C2OR1rZr2B3gA1a9b80/41a9ZQvnx5atWqhZnlV2TJhbuTkpLCmjVrqF27dtBxRERECiXVMcE60nomL9Mt1gI1wrarh9oO5i2gU9aGmVUHPgC6u/vKnA5w91HunujuiZUr//kpHHv27KFixYr6ixVhZkbFihX1k6+IiMhRUB0TrCOtZ/JSJM8B6ppZbTOLBboA47NdvG7YZntgeaj9OGAiMMjdvz6sZNnoL1Yw9LmLiIgcPf17Gqwj+fxzLZLdPQ3oD0wBFgPvuPtCMxtiZh1D3fqb2UIzm0/mvOSsqRb9gVOA+0OPh5tvZlUOO2XAUlJSaNKkCU2aNKFq1apUq1Zt/3Zqauohj01KSmLAgAG5XuPcc8/Nr7giIiIi+xWmOubLL7/k8ssvz5dzHa08zUl290nApGxt94e9vuMgxz0MPHw0AaNBxYoVmT9/PgAPPvgg8fHx/O1vf9u/Py0tjZIlc/4oExMTSUxMzPUa33zzTf6EFREREQmjOubI5GkxEfmzHj160KdPH84++2zuvvtuvvvuO1q0aEHTpk0599xzWbp0KXDgT0QPPvggPXv2pFWrVtSpU4dnnnlm//ni4+P392/VqhVXX3019erVo1u3brg7AJMmTaJevXqceeaZDBgwIMeftFavXs35559Ps2bNaNas2QF/aR977DEaNmxI48aNGTQoc02YFStW0Lp1axo3bkyzZs1YuTLHaeMixcqEpRP4ds23QccostZtX8eouaP4ffvvuXcWkQIRrXVMuM2bN9OpUycaNWrEOeecw4IFCwCYPn36/pHwpk2bsn37dtatW8cFF1xAkyZNaNCgATNnzjzqzyjqlqUuTNasWcM333xDTEwM27ZtY+bMmZQsWZLPPvuMe+65h//+979/OmbJkiVMmzaN7du3c9ppp9G3b98/PY5k3rx5LFy4kBNPPJHzzjuPr7/+msTERG677TZmzJhB7dq16dq1a46ZqlSpwtSpUylTpgzLly+na9euJCUlMXnyZD766CO+/fZbypUrx+bNmwHo1q0bgwYN4sorr2TPnj1kZGTk/wclUogk70zm5o9u5vTKpzOjxwzNIywAq7es5raPb2PS9ZM4sfyJQccRKbaisY4J98ADD9C0aVM+/PBDvvjiC7p37878+fN58sknGT58OOeddx47duygTJkyjBo1iksuuYR7772X9PR0du3addSfT6Erku/85E7mr5+fr+dsUrUJw9oNO+zjrrnmGmJiYgDYunUrN910E8uXL8fM2LdvX47HtG/fntKlS1O6dGmqVKnChg0bqF69+gF9mjdvvr+tSZMmrF69mvj4eOrUqbP/0SVdu3Zl1KhRfzr/vn376N+/P/PnzycmJoZly5YB8Nlnn3HzzTdTrlw5ACpUqMD27dtZu3YtV155JZD5DEGR4m7glIFs27uNFy5/QQVyAUmITwBgw84NAScRiTzVMYeuY8J99dVX+wv1iy66iJSUFLZt28Z5553HXXfdRbdu3bjqqquoXr06Z511Fj179mTfvn106tSJJk2aHPbnkZ2mWxyFuLi4/a/vu+8+LrzwQn766ScmTJhw0MeMlC79vwUHY2JiSEtLO6I+BzN06FASEhL44YcfSEpKynVCvoj8z5QVU3jjxzcY/JfB1K9cP+g4RVZCXKhI3qEiWSRI0VjH5MWgQYN48cUX2b17N+eddx5LlizhggsuYMaMGVSrVo0ePXrw6quvHvV1Ct1I8pH8pBQJW7dupVq1agCMGTMm389/2mmnsWrVKlavXk2tWrV4++23D5qjevXqlChRgrFjx5Keng5AmzZtGDJkCN26dds/3aJChQpUr16dDz/8kE6dOrF3717S09P3jzaLFCc7U3fSZ2If6lWqxz3n3xN0nCItLjaOuFJxGkmWYkl1zKHrmHDnn38+b7zxBvfddx9ffvkllSpV4phjjmHlypU0bNiQhg0bMmfOHJYsWULZsmWpXr06t956K3v37uX777+ne/fuR5VZI8n55O6772bw4ME0bdo0339iAihbtiwjRoygXbt2nHnmmZQvX55jjz32T/369evH2LFjady4MUuWLNn/U2K7du3o2LEjiYmJNGnShCeffBKA1157jWeeeYZGjRpx7rnnsn79+nzPLlIY3D/tflZvWc3oDqMpXbJ07gdEMTNrZ2ZLzWyFmQ3KYX8PM0sOezRnr2z7jzGzNWb2XEFlrBpflfU79P1GJFpESx0T7sEHH2Tu3Lk0atSIQYMGMXbsWACGDRtGgwYNaNSoEaVKleLSSy/lyy+/pHHjxjRt2pS3336bO+7I8cFrh8Wy7jiMFomJiZ6UlHRA2+LFizn99NMDShQ9duzYQXx8PO7O7bffTt26dRk4cGCBX1efvxR1Sb8ncfaLZ3Nrs1t5/vLnj+pcZjbX3XN/XlIBMbMYYBnQBlhD5oJQXd19UVifHkCiu/c/yDmeBioDmw/WJ1xO37dzc97L51GmZBk+7/75YR0nUhjp39FMQdUxWXL6Ohzqe7ZGkguR0aNH06RJE8444wy2bt3KbbfdFnQkkUJvX/o+bp1wKwlxCTzW+rGg4+SH5sAKd1/l7qnAW8AVeT3YzM4EEoBPCygfkDkvWXOSRYqXwlbHFLo5ycXZwIEDI/oTl0hxMHT2UOavn89/r/0vx5Y59K/+ColqwG9h22uAs3Po19nMLiBz1Hmgu/9mZiWA/wA3AK0PdREz6w30BqhZs+Zhh0yIS2Dmr0f/HFMRKTwKWx2jkWQRKbZWbl7JA18+QKd6nbjq9KuCjhNJE4Ba7t4ImAqMDbX3Aya5+5rcTuDuo9w90d0TK1eufNgBEuITSNmVQlpG/s99FBHJD4VmJNnd9czSAETbnHWR/OLu3PbxbZQqUYrnLi2w+9OCsBaoEbZdPdS2n7unhG2+CDweet0CON/M+gHxQKyZ7XD3P938d7QS4hJwnOSdyZxQ/oT8Pr1I1FEdE6wjqWcKxUhymTJlSElJUcEWYe5OSkqKFhmRIunVH17l858/59HWj1LtmGpBx8lPc4C6ZlbbzGKBLsD48A5mFl6VdgQWA7h7N3ev6e61gL8BrxZEgQxaUESKF9UxwTrSeqZQjCRXr16dNWvWkJycHHSUYqdMmTJ/WklHpLDbuHMjd316F+fWOJc+iX2CjpOv3D3NzPoDU4AY4GV3X2hmQ4Akdx8PDDCzjkAasBnoEemcWlBEihPVMcE7knqmUBTJpUqV2r+MoYjI0bpryl1s37ud0R1GU8IKxS/UDou7TwImZWu7P+z1YGBwLucYA4wpgHjA/0aS9axkKQ5UxxRORe9fBxGRQ9DS09GhanxVQNMtRCR6qUgWkWJDS09Hj/jYeMqVKqfpFiIStQrFdAsRkfyQtfT0zJtnFvqlp4uChLgEjSSLSNTSSLKIFAtJvycx7Nth3Hbmbfyl5l+CjiNkzktWkSwi0UpFsogUeUVw6ekiQUtTi0g0U5EsIkVe1tLTz132XFFZerpI0HQLEYlmKpJFpEgrxktPR72E+AQ27dpEekZ60FFERP5ERbKIFFlZS0/HxsQWtaWni4SEuAQyPINNuzYFHUVE5E9UJItIkbV/6emLi9zS00WCFhQRkWimIllEiqRftvyyf+np2xJvCzqO5EALiohINFORLCJFirszeu5oGo5sSGp6apFderooSIjLHEnWEy5EJBrpXw4RKTJ+2fILl7x+Cb0/7k3iiYn80OcHLT0dxbKmW2gkWUSikVbcE5FCL8MzGDV3FH+f+ncARrYfSe8ze2sEOcqVjy1PmZJlNJIsIlFJRbKIFGo///EzvSb04oufv6B1nda82OFFTjrupKBjSR6YmZ6VLCJRS0WyiBRKGZ7ByDkj+cdn/6CElWDU5aPo1awXZhZ0NDkMWppaRKKVimQRKXRWbl7JLeNvYfov02l7cltGdxhNzWNrBh1LjkBCXAK/bv016BgiIn+iCXsiUmhkeAbPfvssjZ5vxLz183ip40t80u0TFciFmKZbiEi0ylORbGbtzGypma0ws0E57O9jZj+a2Xwz+8rM6oftGxw6bqmZXZKf4UWk+FixeQWtxrRiwCcDaHlSSxb2W0jPpj01vaKQS4hPYOPOjVqaWkSiTq5FspnFAMOBS4H6QNfwIjjkTXdv6O5NgMeBp0LH1ge6AGcA7YARofOJiORJekY6w2YPo9HIRizYsIAxV4xh4vUTqX5M9aCjST6oGl+VDM8gZXdK0FFERA6QlznJzYEV7r4KwMzeAq4AFmV1cPdtYf3jAA+9vgJ4y933Aj+b2YrQ+WblQ3YRKeI27tzIte9ey/RfpnP5qZfzfPvntbx0ERO+oEiVuCoBpxER+Z+8FMnVgN/CttcAZ2fvZGa3A3cBscBFYcfOznas/oUTkVz9uOFHOozrwIadGxhzxRi6N+6uqRVFUPiCIg1pGHAaEZH/ybcb99x9uLufDPwD+OfhHGtmvc0sycySkpOT8yuSiBRSHy/7mHNfPpd9GfuYefNMbmpykwrkIkpLU4tItMpLkbwWqBG2XT3UdjBvAZ0O51h3H+Xuie6eWLly5TxEEpGiyN158psn6TiuI6dVPI3ven1H4omJQceSAqSlqUUkWuWlSJ4D1DWz2mYWS+aNeOPDO5hZ3bDN9sDy0OvxQBczK21mtYG6wHdHH1tEiprU9FRuGX8Lf5/6d66ufzUzbp6h+cfFwLGljyU2JlYjySISdXKdk+zuaWbWH5gCxAAvu/tCMxsCJLn7eKC/mbUG9gF/ADeFjl1oZu+QeZNfGnC7u+s5PyJygOSdyXR+pzMzf53JAy0f4P6W91PC9Bj34kBLU4tItMrTinvuPgmYlK3t/rDXdxzi2H8B/zrSgCJStP208Sc6jOvA+h3rGdd5HF0adAk6kkSYlqYWkWikZalFJDCTlk+iy3tdiI+NZ3qP6TSv1jzoSBKAhLgE1m4/1K0uIiKRp99nikjEuTtDZw2lw7gOnFLhFL679TsVyMVY1fiqmpMsIlFHI8kiElGp6an0m9iPl+a9ROfTOzO201jiYuOCjiUBSojLXJo6wzM0F11Eooa+G4lIxGzatYk2r7XhpXkv8c/z/8k717yjAllIiE8g3dPZvHtz0FFERPbTSLKIRMSi5EV0GNeBtdvW8sZVb3B9w+uDjiRRInxBkUrlKgWcRkQkk0aSRaRApWek88q8V2jxUgt2pu5keo/pKpDlAFpQRESikUaSRaRAuDsTl09k0GeDWJi8kHOqn8M7V79DjWNr5H6wFCtamlpEopFGkkUk381eM5tWY1vRYVwHUtNTefead/mm5zcqkCPEzNqZ2VIzW2Fmg3LY38PMks1sfui/XqH2JmY2y8wWmtkCM7suEnk1kiwi0UgjySKSb5ZuWso9X9zD+4vfJyEugRGXjaBXs16UiikVdLRiw8xigOFAG2ANMMfMxrv7omxd33b3/tnadgHd3X25mZ0IzDWzKe6+pSAzH1/meEqVKKWRZBGJKiqSReSordu+jv83/f/x4vcvUrZUWYa0GsLAFgOJj40POlpx1BxY4e6rAMzsLeAKIHuR/Cfuvizs9e9mthGoDBRokWxmVImrwvqd6wvyMiIih0VFsogcsa17tvLEN08wdPZQ9qXvo99Z/fjnBf+kSlyVoKMVZ9WA38K21wBn59Cvs5ldACwDBrp7+DGYWXMgFlhZUEHDaUEREYk2KpJF5LDtTdvL80nP89CMh0jZnUKXBl14+MKHObnCyUFHk7yZAIxz971mdhswFrgoa6eZnQC8Btzk7hk5ncDMegO9AWrWrHnUgRLiE1i/QyPJIhI9dOOeiORZhmfwxoI3qDe8HndOuZMmVZuQdGsS4zqPU4EcPdYC4XdIVg+17efuKe6+N7T5InBm1j4zOwaYCNzr7rMPdhF3H+Xuie6eWLly5aMOnRCXoJFkEYkqGkkWkTzZtW8XF796MbPXzKZp1aaMumEUbU5uE3Qs+bM5QF0zq01mcdwFOODB1GZ2gruvC212BBaH2mOBD4BX3f29yEX+39LU7o6ZRfLSIiI5UpEsInly3xf3MXvNbF7q+BI9mvSghOkXUdHI3dPMrD8wBYgBXnb3hWY2BEhy9/HAADPrCKQBm4EeocOvBS4AKppZVlsPd59f0LkT4hPYl7GPP/b8QYWyFQr6ciIiuVKRLCK5mvXbLIbOHkq/xH70bNoz6DiSC3efBEzK1nZ/2OvBwOAcjnsdeL3AA+YgfEERFckiEg00FCQih7QnbQ89x/ekxrE1eLT1o0HHkSJKC4qISLTRSLKIHNKQ6UNYsmkJU26YQvnS5YOOI0WUlqYWkWijkWQROai5v8/l8a8fp2eTnrQ9uW3QcaQIqxpfFUCPgRORqKEiWURylJqeSs/xPakSV4X/XPKfoONIEXd82eMpWaKkpluISNTQdAsRydEjMx9hwYYFfNTlI44rc1zQcaSIK2ElqBJXRdMtRCRqaCRZRP5kwYYFPDzzYa5veD0dT+sYdBwpJhLiEjSSLCJRQ0WyiBwgLSONnh/1pELZCjzT7pmg40gxkhCvIllEooeKZBE5wH+++Q9z181l+GXDqViuYtBxpBjR0tQiEk1UJIvIfks2LeGBLx+g8+mdubr+1UHHkWIma7qFuwcdRURERbKIZErPSKfnRz2Ji43jucueCzqOFEMJ8Qmkpqeyde/WoKOIiKhIFpFMz373LLPWzOLpdk/vf2atSCRlLSiiZyWLSDRQkSwirNy8kns+v4f2ddvTrWG3oONIMZX1w5nmJYtINFCRLFLMZXgGvSb0olRMKZ6//HnMLOhIUkwlxIeWptYTLkQkCmgxEZFibtTcUXy5+ktGdxhN9WOqBx1HirGs6RYaSRaRaKCRZJFi7Netv/L3qX+ndZ3W3NL0lqDjSDFXsVxFYixGI8kiEhVUJIsUU+7OrRNuxd0Z3WG0pllI4EpYCSrHVdZIsohEhTwVyWbWzsyWmtkKMxuUw/67zGyRmS0ws8/N7KSwfY+b2UIzW2xmz5j+JRbZ74FpD3DuS+dy3xf3MeOXGaSmp0bs2mPmj+HTlZ/yWOvHqHVcrYhdV+RQtDS1iESLXItkM4sBhgOXAvWBrmZWP1u3eUCiuzcC3gMeDx17LnAe0AhoAJwFtMy39CKF2Pod63n060dZvWU1j3z1CC3HtKTCYxW4/M3LeXr20yxKXlRgiyr8vv13Bk4ZyPk1z6fvWX0L5BoiR0JLU4tItMjLjXvNgRXuvgrAzN4CrgAWZXVw92lh/WcDN2TtAsoAsYABpQB99xMBRswZwb70fUzvMZ0qcVWYtnoaU1dOZeqqqUxcPhGAauWr0ebkNrSp04bWdVpTJa7KUV/X3enzcR/2pu/lpY4vUcI060qiR0JcAks3LQ06hohInorkasBvYdtrgLMP0f8WYDKAu88ys2nAOjKL5OfcfXH2A8ysN9AboGbNmnlLLlKI7d63m5FJI7n81MupW7EuAJ3qdaJTvU4A/LLlF6aumsqnKz9l/NLxjJk/BoDGCY1pU6cNbU5uw/k1z6dMyTLs2reLHak72J66PfPPvdsPeJ21L+v1uh3rmLBsAk+2eXL/tUWiRUJcAut3rMfdNU9eRAKVr4+AM7MbgERCUyrM7BTgdCDruVJTzex8d58Zfpy7jwJGASQmJhbM75dFosjrC15n065NDDxnYI77TzruJHo160WvZr1Iz0hn3vp5+0eZn/nuGZ6c9SQxFoPjZHhGnq4ZGxNL+djyxMfG061hN+485878fEsi+aJqfFX2pu9l295tHFvm2KDjiEgxlpcieS1QI2y7eqjtAGbWGrgXaOnue0PNVwKz3X1HqM9koAUwM/vxIsWFuzPs22E0qdqEVrVa5do/pkQMiScmknhiIoPPH8zO1J3M/HUmX/36FYZRvnRm4ZtVAIdvZ72Oj40nNia24N+cyFEKX1BERbKIBCkvRfIcoK6Z1SazOO4CXB/ewcyaAi8A7dx9Y9iuX4FbzewRMqdbtASG5UdwkcLq05Wfsih5EWM7jT2iXyfHxcbR7pR2tDulXQGkEwlW+IIip1Y8NeA0IlKc5XrHjrunAf2BKcBi4B13X2hmQ8ysY6jbE0A88K6ZzTez8aH294CVwI/AD8AP7j4hv9+ESGEydPZQqsZXpUuDLkFHEYk6WppaRKJFnuYku/skYFK2tvvDXrc+yHHpwG1HE1CkKFm4cSFTVk7h4Qsf1vQHkRxoaWoRiRZ69pNIBA2bPYwyJctwW6J+dhTJSaCAiSsAACAASURBVKVylShhJTSSLCKBU5EsEiHJO5N5bcFrdG/UnUrlKgUdRyQqxZSIoVK5ShpJFpHAqUgWiZCRSSPZm75Xj14TyYWWphaRaKAiWSQC9qbtZcScEVx6yqWcXvn0oOOIRLWE+MwFRUREgqQiWSQCxv00jg07Nxx08RAR+Z+q8VU1kiwigVORLFLA3J2hs4fSoEoDWtfJ8UEwIhImIS6BDTs24K4FWEUkOCqSRYCdqTsZO38s3639Lt/P/cXPX7BgwwIGnjPwiBYPESluEuIS2J22mx2pO4KOIiLFWJ6ekyxSVC1LWcaIOSMYM38MW/du5ZjSx/Btr2+pV6levl1j6OyhVImrwvUNr8+9s4gcsKBI+dLlA04jIsWVRpKl2EnLSOOjJR/R9rW2nPbcaYyYM4LL6l7Gh9d9SNmSZekwrgObd2/Ol2st3bSUicsn0i+xH2VKlsmXc4oUdVpQRESigYpkKTY27tzIv2f+m5OfOZlOb3di8abFPHThQ/w68Ffe7PwmV9S7gg+u+4Bft/7KNe9ew770fUd9zWGzh1E6pjR9z+qbD+9AJG/MrJ2ZLTWzFWY2KIf9Pcws2czmh/7rFbbvJjNbHvrvpsgmz6SlqUUkGmi6hRRp7s7sNbMZPmc47y56l9T0VC6qfRFDLxlKx9M6UrLEgf8LtKjRghc7vEj3D7szYPIARrQfccTziFN2pTD2h7F0a9iNKnFV8uPtiOTKzGKA4UAbYA0wx8zGu/uibF3fdvf+2Y6tADwAJAIOzA0d+0cEou+nkWQRiQYqkqVI2rVvF2/++CYj5oxg3vp5lI8tT+9mvel3Vr9cn1N8Y+MbWZi8kMe+fowzqpxB/+b9D9n/YEbNHcXutN0MbKHHvklENQdWuPsqADN7C7gCyF4k5+QSYKq7bw4dOxVoB4wroKw5qhxXGcM0kiwigVKRLEXK5t2beXjGw7wy/xW27NlCgyoNGNl+JDc0uoH42Pg8n+ffF/+bxZsWc+cnd3JaxdNoc3Kbw8qRmp7Ks989S5s6bWhQpcHhvg2Ro1EN+C1sew1wdg79OpvZBcAyYKC7/3aQY6sVVNCDKVmiJBXLVdSCIiISKM1JliIjeWcyrca04tnvnqXtyW2Z3mM6C/osoE9in8MqkAFKWAlev/J16leuzzXvXsPSTUsP6/h3Fr7Duh3rtHiIRKsJQC13bwRMBcYe7gnMrLeZJZlZUnJycr4H1IIiIhI0FclSJGzYsYELx17I8s3LmdxtMm9f/TYXnHTBUT2XuHzp8ozvOp7YmFg6vtWRP3bnbVpm1uIhp1c6nUtOueSIry9yhNYCNcK2q4fa9nP3FHffG9p8ETgzr8eGnWOUuye6e2LlypXzJXi4rAVFRESCoiJZCr1129fRamwrft7yM5Oun5Svq9rVOq4W71/3Pj//8TPXvndtnp54MfPXmXy/7nvuPOdOSpj+F5OImwPUNbPaZhYLdAHGh3cwsxPCNjsCi0OvpwBtzex4MzseaBtqi7iE+ASNJItIoPQvuBRqa7etpeWYlvy29Tcmd5vMhbUvzPdr/KXmXxjVYRSfrfqMgVNynz7x1KynqFi2Ijc2ujHfs4jkxt3TgP5kFreLgXfcfaGZDTGzjqFuA8xsoZn9AAwAeoSO3Qw8RGahPQcYknUTX6RpJFlEgqYb96TQ+nXrr1w09iI27tzIlBumcF7N8wrsWj2a9GDhxoU8OetJzqh8xkGfe7xi8wrGLx3PveffS9lSZQssj8ihuPskYFK2tvvDXg8GBh/k2JeBlws0YB4kxCWwc99OdqbuJC42Lug4IlIMaSRZCqXVW1bTckxLkncl8+mNnxZogZzl0daP0r5ue/5v8v/x+arPc+zzzLfPULJESfqd1a/A84gUZVpQRESCpiJZCp1Vf6yi5ZiWbNmzhc+7f8451c+JyHVjSsTwZuc3qVepHte8ew3LU5YfsH/Lni28PO9lujbsygnlTzjIWUQkL7SgiIgETUWyFCrLU5bTckxLdqTu4PPun5N4YmJEr39M6WMY33U8JawEHcZ1YMueLfv3jZ47mp37duqxbyL5QCPJIhI0FclSaCzdtJSWY1qyJ20PX3T/gmYnNAskR53j6/Dfa//Lyj9Wct1715GWkUZaRhrPfvcsF9a6kCZVmwSSS6QoyRpJ1oIiIhIUFclSKCxKXkTLMS1J93Sm3TSNxlUbB5qnZa2WjGw/kk9Xfspfp/yV/y76L79t+02jyCL5pEpcFUDTLUQkOHq6hUS9nzb+xEVjLyKmRAzTuk/j9MqnBx0JgF7NerFw40KGfTuMN358g7oV6tL+1PZBxxIpEkrFlKJi2YqabiEigdFIskS1H9b/QKsxrSgVU4ovb/oyagrkLE+0fYJ2p7QjZXeKFg8RyWdaUEREgqSRZIla36/7njavtaFcqXJMu2kap1Q4JehIf1KyREnevvpt3lv0Hjc0uiHoOCJFihYUEZEgadhLotKctXO4+NWLiY+NZ3qP6VFZIGc5pvQx9Gzak9iY2KCjiBQpGkkWkSCpSJaosyN1B5e9eRnHlzme6T2mU+f4OkFHEpEAaCRZRIKkIlmizpj5Y9i0axOvX/U6tY6rFXQcEQlIQlwC21O3s3vf7qCjiEgxpCJZokqGZ/D0t09zTvVzOLfGuUHHEZEAaUEREQmSimSJKh8v+5gVm1foecMiogVFRCRQeSqSzaydmS01sxVmNiiH/XeZ2SIzW2Bmn5vZSWH7aprZp2a2ONSnVv7Fl6LmqVlPUfPYmlx1+lVBRxGRgFWNrwpoQRERCUauRbKZxQDDgUuB+kBXM6ufrds8INHdGwHvAY+H7XsVeMLdTweaAxvzI7gUPfPWzWP6L9MZ0HwAJUvo6YQixZ2mW4hIkPIyktwcWOHuq9w9FXgLuCK8g7tPc/ddoc3ZQHWAUDFd0t2nhvrtCOsncoChs4cSHxtPr2a9go4iIlFAS1OLSJDyUiRXA34L214TajuYW4DJodenAlvM7H0zm2dmT4RGpkUO8Pv23xn30zh6NunJsWWODTqOiESB2JhYji9zvEaSRSQQ+XrjnpndACQCT4SaSgLnA38DzgLqAD1yOK63mSWZWVJycnJ+RpJCYvh3w0nPSOeOc+4IOoqIRBEtKCIiQclLkbwWqBG2XT3UdgAzaw3cC3R0972h5jXA/NBUjTTgQ6BZ9mPdfZS7J7p7YuXKlQ/3PUght2vfLp6f+zyd6nXSwiEicgAtKCIiQclLkTwHqGtmtc0sFugCjA/vYGZNgRfILJA3Zjv2ODPLqnwvAhYdfWwpSl774TU2796sx76JyJ9oJFlEgpJrkRwaAe4PTAEWA++4+0IzG2JmHUPdngDigXfNbL6ZjQ8dm07mVIvPzexHwIDRBfA+pJDK8AyGzh7KmSecyV9q/iXoOCISZRLiEvScZBEJRJ6es+Xuk4BJ2druD3vd+hDHTgUaHWlAKdo+WfEJS1OW8sZVb2BmQccRkSiTEJfAtr3b2JO2hzIlywQdR0SKEa24J4EaOnso1cpX45r61wQdRUSikBYUEZGgqEiWwCzYsIDPVn1G/+b9KRVTKug4IhKFtKCIiARFRbIEZtjsYZQrVY7eZ/YOOoqIRKmEuFCRrJFkEYkwFckSiA07NvDGj2/Qo3EPKpStEHQcEYlSGkkWkaCoSJZAjJgzgtT0VC0eIiKHpKWpRSQoKpIl4vak7WFk0kg6nNqBUyueGnQcEYliZUqW4djSx2okWUQiTkWyRNwbC94geVeyFg8RkTzRgiIiEgQVyRJR7s7Q2UNpnNCYVrVaBR1HRAoBLSgiIkFQkSwRNXXVVBYmL+SuFndp8RARyZOE+ATNSRaRiFORLBE1dPZQqsZXpUuDLkFHEZFCompcVU23EJGIU5EsEbMoeRGfrPiE28+6ndiY2KDjiEghkRCfwJY9W9ibtjfoKCJSjKhIlogZNnsYZUqWoU9in6CjiEghkrWgyMadGwNOIiLFiYpkiYhNuzbx2oLX6N6oO5XKVQo6jkiRZmbtzGypma0ws0GH6NfZzNzMEkPbpcxsrJn9aGaLzWxw5FIfnBYUEZEgqEiWiHg+6Xn2pO3hznPuDDqKSJFmZjHAcOBSoD7Q1czq59CvPHAH8G1Y8zVAaXdvCJwJ3GZmtQo6c260NLWIBEFFshS4vWl7ee6757j0lEs5vfLpQccRKeqaAyvcfZW7pwJvAVfk0O8h4DFgT1ibA3FmVhIoC6QC2wo4b640kiwiQVCRLAXurZ/eYsPODVo8RCQyqgG/hW2vCbXtZ2bNgBruPjHbse8BO4F1wK/Ak+6+uQCz5olGkkUkCCqSpUBlLR7SoEoDWtdpHXQckWLPzEoATwF/zWF3cyAdOBGoDfzVzOoc5Dy9zSzJzJKSk5MLLC9A2VJlKR9bXguKiEhEqUiWAjVt9TR+2PADA88ZqMVDRCJjLVAjbLt6qC1LeaAB8KWZrQbOAcaHbt67HvjE3fe5+0bgayAxp4u4+yh3T3T3xMqVKxfA2ziQlqYWkUhTkSwFaujsoVSJq8L1Da8POopIcTEHqGtmtc0sFugCjM/a6e5b3b2Su9dy91rAbKCjuyeROcXiIgAziyOzgF4S6TeQk6rxWlBERCJLRbIUmGUpy/h42cf0TexLmZJlgo4jUiy4exrQH5gCLAbecfeFZjbEzDrmcvhwIN7MFpJZbL/i7gsKNnHeJMRpaWoRiaySQQeQoumnjT9x7bvXUqZkGfom9g06jkix4u6TgEnZ2u4/SN9WYa93kPkYuKiTEJfAtNXTgo4hIsWIRpIlX7k7o+aO4qzRZ7F592Y+7vrx/sc3iYgcqYT4BDbv3sy+9H1BRxGRYkIjyZJvtu7Zyq0TbuXdRe/S9uS2vNrpVRXIIpIvwpemrnZMtVx6i4gcPY0kS774bu13NH2hKe8vfp9HL36Uyd0mq0AWkXyjBUVEJNI0kixHJcMzeGrWUwz+fDDVyldj5s0zaVGjRdCxRKSI0YIiIhJpKpLliCXvTOamD29i8orJXHX6VbzY4UWOL3t80LFEpAjKGknWgiIiEikqkuWITPt5Gt3e78bm3ZsZcdkI+iT20WIhIlJg9o8ka7qFiESI5iTLYUnLSOOBaQ9w8asXc0zpY/i217f0PauvCmQRKVBxsXHEx8ZruoWIRIxGkiXP1mxbw/X/vZ6Zv86kR5MePHfpc8TFxgUdS0SKiYQ4LU0tIpGjIlnyZMLSCfT4qAd70/by2pWvcUOjG4KOJCLFTEK8imQRiRxNt5BDyvAM/jrlr3R8qyMnHXsS39/2vQpkEQmElqYWkUjKU5FsZu3MbKmZrTCzQTnsv8vMFpnZAjP73MxOyrb/GDNbY2bP5VdwiYyHpj/EU7Of4vazbmfWLbM4teKpQUcSkWJK0y1EJJJyLZLNLAYYDlwK1Ae6mln9bN3mAYnu3gh4D3g82/6HgBlHH1ciafzS8Tw4/UG6N+7Os5c+S+mSpYOOJCLFWEJ8Aim7UkjLSAs6iogUA3kZSW4OrHD3Ve6eCrwFXBHewd2nufuu0OZsoHrWPjM7E0gAPs2fyBIJSzct5cYPbuTME87k+fbP6+kVIhK4hLgEHCd5Z3LQUUSkGMhLkVwN+C1se02o7WBuASYDmFkJ4D/A3440oETetr3b6PR2J0rHlOb9696nbKmyQUcSEdGCIiISUfn6dAszuwFIBFqGmvoBk9x9zaFGIs2sN9AboGbNmvkZSQ5ThmfQ/YPuLE9ZzmfdP6Pmsfp6iEh0qBpfFdCCIiISGXkpktcCNcK2q4faDmBmrYF7gZbuvjfU3AI438z6AfFArJntcPcDbv5z91HAKIDExEQ/7Hch+eZfM/7FR0s/Ytglw2hVq1XQcURE9tu/6p6ecCEiEZCXInkOUNfMapNZHHcBrg/vYGZNgReAdu6+Mavd3buF9elB5s19f3o6hkSHj5d9zANfPsCNjW5kwNkDgo4jInKArOkWGkkWkUjIdU6yu6cB/YEpwGLgHXdfaGZDzKxjqNsTZI4Uv2tm881sfIEllgKxLGUZ3d7vRpOqTXjh8hd0o56IRJ342HjKlSqnkWQRiYg8zUl290nApGxt94e9bp2Hc4wBxhxePImE7Xu30+mtTsTGxPLBdR/oRj0RiVp6VrKIRIqWpS7mMjyDmz68iWUpy5h641ROOu6k3A8SEQmIlqYWkUjRstTF3CMzH+GDJR/wRJsnuLD2hUHHERE5pBPLn8ii5EXsSdsTdBQRKeJUJBdjE5dN5L5p99GtYTfuPOfOoOOIiOSqb2Jfft/+Ow9NfyjoKCJSxKlILqaWpyyn2/vdaFy1MaM6jNKNeiJSKLSu05oeTXrw+DeP88P6H4KOIyJFmIrkQmTb3m38a8a/mLB0Arv27cr9gIPYvnc7nd7uRMkSJfngug8oV6pcPqYUESlY/2n7HyqUrUCvCb1Iy0gLOo6IFFG6ca+Q2Jm6k/ZvtuerX78CoHRMaS6qfRHt67an/antqXVcrTydx93p8VEPlmxawqc3fJrn40REokWFshV49tJnue6963jm22e4q8VdQUcSkSJII8mFwO59u+n4Vke++e0b3rjqDabeOJW+iX1Zvnk5/Sf3p/bTtWkwogGDPhvEzF9mHnJk5ZGvHuH9xe/zRJsnuLjOxRF8FyIi+eea+tfQ4dQO/POLf7Lqj1VBxxGRIsjco2sV6MTERE9KSgo6RtTYm7aXTm93YsqKKbx65avc0OiGA/YvS1nGx8s+ZuLyicz4ZQZpGWkcX+Z42p3SjvZ129PulHZULFcRgMnLJ9P+zfZ0bdiV1698XfOQRQqAmc1198Sgc0RSUN+312xbQ/3h9Tm7+tl8esOn+p4mIoftUN+zVSRHsdT0VK559xrGLx3Pix1e5JZmtxyy/9Y9W5m6aioTl09k4rKJJO9KpoSVoEX1FrQ9uS1DZw/lpGNP4ptbvtE8ZJECoiI5skbOGUm/Sf0Yc8UYbmpyUyAZRKTwUpFcCKVlpNH1v115b9F7DL9sOP3O6ndYx2d4Bkm/J+0fZf5+3fdUKFuBpFuTqH187QJKLSIqkiMrwzNoOaYlCzcuZPHti0mITwgkh4gUTof6nq05yVEoPSOdmz68ifcWvcdTbZ867AIZoISVoHm15gy5cAhze89l7V1r+bHvjyqQRaRIKWElGN1hNDv37eSOT+4IOo6IFCEqkqNMhmfQe0Jv3vzxTR65+BEGthiYL+c9sfyJnFj+xHw5l4hINKlXqR73XXAfby98mwlLJwQdR0SKCBXJUcTd6T+pPy/Pf5kHWj7AoL8MCjqSiEihcPd5d9OgSgP6TerHtr3bgo4jIkWAiuQo4e7cNeUuRiaN5B/n/YMHWj4QdCQRkUIjNiaWlzq+xNptaxn82eCg44hIEaAiOQq4O4M/H8ywb4dxx9l38MjFj+hRRiIih6l5tebccfYdjEgawde/fh10HBEp5FQkR4Eh04fw2NeP0efMPgy9ZKgKZBE5KmbWzsyWmtkKMzvovC0z62xmbmaJYW2NzGyWmS00sx/NrExkUuePhy56iJOOPYleE3qxJ21P0HFEpBBTkRywR796lAenP8jNTW5mePvhKpBF5KiYWQwwHLgUqA90NbP6OfQrD9wBfBvWVhJ4Hejj7mcArYB9EYidb+Jj43nh8hdYsmkJ/57576DjiEghpiI5QMNmD2Pw54O5vuH1jO4wmhKmL4eIHLXmwAp3X+XuqcBbwBU59HsIeAwIH25tCyxw9x8A3D3F3dMLOnB+u+SUS7ix0Y088tUj/Ljhx6DjiEghpaosICPnjGTglIF0Pr0zYzuNJaZETNCRRKRoqAb8Fra9JtS2n5k1A2q4+8Rsx54KuJlNMbPvzezugo1acJ665CmOK3Mct064lfSMQlfni0gUUJEcYRmewdOzn6bfpH50OLUDb3Z+k5IlSgYdS0SKCTMrATwF/DWH3SWBvwDdQn9eaWYXH+Q8vc0sycySkpOTCyzvkapUrhLPtHuGb9d+y3PfPRd0HBEphFQkR9CXq78kcVQid065k/Z12/PuNe8SGxMbdCwRKVrWAjXCtquH2rKUBxoAX5rZauAcYHzo5r01wAx33+Tuu4BJQLOcLuLuo9w90d0TK1euXABv4+h1adCFy+pexr1f3MvqLauDjiMihYyK5AhYsXkFV759JReOvZCU3Sm8edWbTOg6gdIlSwcdTUSKnjlAXTOrbWaxQBdgfNZOd9/q7pXcvZa71wJmAx3dPQmYAjQ0s3Khm/haAosi/xbyh5kxsv1IzIw+H/fB3YOOJCKFiIrkAvTH7j+4a8pd1B9en89Wfca/LvoXS25fQteGXfUUCxEpEO6eBvQns+BdDLzj7gvNbIiZdczl2D/InIoxB5gPfJ/DvOVCpeaxNXnk4keYsnIKb/z4RtBxRKQQsWj7yToxMdGTkpKCjnFU9qXv4/mk53lw+oP8sfsPbml6Cw9d9BBV46sGHU1ECpiZzXX3xNx7Fh3R/n07PSOd8185n2Upy5jbey4nHXdS0JFEJEoc6nu2RpLzkbvz8bKPaTiyIQM+GUCTqk2Yd9s8RnccrQJZRCQgMSVieLHji+zat4vTnjuNOybfwfod64OOJSJRTkVyPlmwYQFtX29Lh3EdcJzxXcbz2Y2f0bhq46CjiYgUe/Ur12fR7Yu4odENDJ8znDpP1+Hvn/6d5J3R92QOEYkOKpKP0vod6+k9oTdNX2jK3N/n8nS7p/mp7090OK2D5h2LiESRWsfV4sWOL7Kk/xKuOeManpr9FLWfrs09n99Dyq6UoOOJSJRRkXyE9qXv45GZj1D32bq8Mv8VBjQfwIoBKxhw9gBKxZQKOp6IiBzEKRVOYWynsSzst5AOp3Xg0a8epfbTtXlg2gNs2bMl6HgiEiVUJB+h/pP6c88X93BR7YtY2G8hQ9sNpULZCkHHEhGRPKpXqR7jOo9jQd8FtD25LUNmDKH207V5eMbDbNu7Leh4IhIwFclHYNTcUYz6fhT/OO8ffNTlI06teGrQkURE5Ag1qNKA9659j3m3zeOCky7gvmn3Ufvp2jz21WPsTN0ZdDwRCYiK5MM067dZ9J/Un0tOvoR/XfSvoOOIiEg+aVK1CR91+Yg5t87h7GpnM+jzQdR+ujZPzXqK3ft2Bx1PRCIsT0WymbUzs6VmtsLMBuWw/y4zW2RmC8zsczM7KdTexMxmmdnC0L7r8vsNRNK67evo/E5nahxbgzc7v0lMiZigI4mISD5LPDGRSd0m8U3Pb2hctTF//fSv+0eWt+7ZGnQ8EYmQXItkM4sBhgOXAvWBrmZWP1u3eUCiuzcC3gMeD7XvArq7+xlAO2CYmR2XX+EjKTU9lavfvZqte7fy4XUfav6xiEgR16JGC6beOJXpPabTuGpjBn0+iJrDajL4s8F6zrJIMZCXkeTmwAp3X+XuqcBbwBXhHdx9mrvvCm3OBqqH2pe5+/LQ69+BjUDl/AofSXdMvoNvfvuGV654hYYJDYOOIyIiEXLBSRcw5YYpzO09l3antOOxrx+j1rBa9P24Lys3rww6nogUkLwUydWA38K214TaDuYWYHL2RjNrDsQChe47yovfv8jzc5/n7nPv5tozrg06joiIBKDZCc14++q3Wdp/KTc1vomX57/Mqc+dSpf3ujBv3byg44lIPsvXG/fM7AYgEXgiW/sJwGvAze6ekcNxvc0sycySkpOja/Wj2Wtmc/uk22l7clv+ffG/g44jIiIBq1uxLi90eIHVd6zmby3+xqTlk2g2qhntXm/Hl6u/xN2Djigi+SAvRfJaoEbYdvVQ2wHMrDVwL9DR3feGtR8DTATudffZOV3A3Ue5e6K7J1auHD2zMdbvWE/ndzpTrXw1xnUepxv1RERkvxPKn8BjbR7j14G/8u+L/s289fO4cOyFtHipBR8u+ZCMP48JiUghUjIPfeYAdc2sNpnFcRfg+vAOZtYUeAFo5+4bw9pjgQ+AV939vXxLHQGp6alc/c7VbNmzhVm3zNKNeiIikqPjyhzH4PMHc+c5dzJm/hie+OYJrnz7SupVqsfd595N82rNATAzDDvgT+BPbUZme/nS5alUrlJg70ukuMu1SHb3NDPrD0wBYoCX3X2hmQ0Bktx9PJnTK+KBd0P/0//q7h2Ba4ELgIpm1iN0yh7uPj//30r+GvjJQL7+7ev/396dR0dR5msc//4Ii5CEPRAIBMIOMVyBqDAsgizicoWg4oLnOsqF0TNemBEV7zjjgnMcEWVAnUFxRMcxbigIKi5cRhRUEGRLwCAgCInsuyBr3vtHN5nQk03oThXp53NOTndXvdX1dHXVy4/qWnjtmtfo2LCj13FERMTnqlepzh0X3sGILiOYvno6j33+GLfNvu2s3vPCxhdyTftrGNJ+CK3rtQ5TUhEpC/PbsVPp6elu6dKlnmaYtnwaw2cP5+5udzNhwITSJxARCTKzr51z6V7nKE9+6Lf9yDnHgs0LCi4X55zD4U57BIodlncgj1lrZ7HkhyVA4M6AQ9oNYUj7IXRs2LFgT7SInLmS+mwVySG+yvuKni/2pFezXnww7AMqVyrLESkiIgEqkiXcNu/fzMxvZjIjZwYLvl+Aw9GyTkuGtA8UzBclXUQl0w10Rc6EiuQy2vbjNtKnplMlpgpLRyylXo16nuQQkXOXimSJpO0/bmf22tnMyJnBvO/mcTz/OEnxSWS0y2BI+yH0bNZTO3dEfoaS+mxtSUHHTh7juunXseenPXwx/AsVyCIi4jsN4xoyossIRnQZwb4j+3j/2/eZkTODF5a/wDNLnqFe9XoMajuIjPYZ9GvRj/Mqn+d1ZJFzlorkoDEfjWHh5oW8OuRVLki8wOs4IiIiJap9Xm2GdRzGsI7DOHz8MB+t/4gZOTN4+5u3mbZiGnFV47i81eVktMvgitZXUOu8Wl5HFjmnqEgGXlrxEs8seYYx3cZwY9qNXscRNvb/kAAAFh5JREFUERH5WWpUqUFG+wwy2mdw7OQxPtn4CTNzZjJr7Symr5lOlUpVuDTlUjLaZXB126tpFN/I68givhf1xyQvyVtCzxd70iO5Bx/e/KGO5RKRs6JjksVP8l0+i3MXMzNnJjNzZrJ+z3oMo2uTrmS0CxTVreq28jqmiGd04l4x8l0+bZ5uw4n8EywduVQXbReRs6YiWfzKOceanWsKCuZlW5cBkJqQSka7DAa3G0znRp11aTmJKjpxrxgLvl/Ahr0byBySqQJZREQqNDMjtUEqqQ1S+X2v3/P9vu95J+cd3ln7Do8ufJQ/LvgjybWSGdx2MIPbDdaVMiTqRfXan5mVSWyVWAa1HeR1FBERkXLVrHYzRncdzeiuo9l1eBfvrn2XmTkzmbpsKk999RR1q9flqjZXMbjtYC5rdRk1qtTwOrJIuYraIvnoiaNMXzOdjPYZxFaN9TqOiIiIZ+rXqM+tnW7l1k63cujYIT7e8DHvrH2Hd9e+y8srX6Z65eoMaDmAwe0Gc1Wbq/Trq0SFqC2S56ybw74j+7g57Wavo4iIiPhGbNXYgitlHD95nAWbFwQOy8h5h1lrZ1HJKtGrWS8Gtx3MoHaDaF67udeRRSIiak/cu+bNa1i4eSF5d+XpmCsRCRuduCcVlXOO5duWFxTMWTuyALgg8QIGtx3MtR2uJbVBqscpRX6ekvrsqLzZ+74j+3jv2/e48fwbVSCLiIiUgZnRuVFnxvUZx6o7VrHuf9bxRP8niKsax8OfPsz5U84nfWo6Ty9+ml2Hd3kdV+SsRWWR/Paatzl28hjD0oZ5HUVEROSc1KpuK8b8YgwLbl3A1jFbmTxwMvkun1EfjqLxk43JeCODWTmzOHbymNdRRc5IVBbJr2S9Qpt6bUhvHFW/iIqIiEREw7iGjLp4FMt+tYxVt69i1MWj+HLLlwx+YzBJE5MY/cFolm1dht8O8RQpSdQVyVv2b+HTTZ8yLG2YLpguIiISZmkN03hiwBPk3pXLeze+R5/mfXj262fpMrULHZ/tyJNfPMm2H7d5HVOkVFFXJL+W/RoOx01pN3kdRUREpMKqXKkyV7a5kjeve5NtY7Yx5copxFaJ5e65d9NkYhOufPVK3lz9JkdOHPE6qkiRou6stcysTLo26ap71YuIiJSTOtXrcHv67dyefjs5u3J4eeXL/GPVP7j+reupVa0WvZv3pkdyD3om96RTo05UjanqdWSR6CqSs7ZnsWr7Kp6+/Gmvo4iIRIyZDQQmAzHA35xzjxXT7hrgLeBC59zSQsOTgTXAQ865J8ohskSRdvXb8WjfR3mkzyP8c+M/eT37dT7b/Bmz1s4CoHrl6lzc5GJ6NO1Bj+QedGvajZrVap7RvJxz/HDwB7J2ZJG1PYusHVlk78jm293fcmnKpYzrM44LEi8I58eTCiSqiuTMrExiLIbrU6/3OoqISESYWQzwF6A/kAssMbPZzrk1Ie3igdHA4iLeZiLwQaSzSnSLqRRD/5b96d+yPwDbftzG55s/Z+HmhSzYvIBHFz5KvsunklWiY8OO9EzuSY/kQOHcOL7xv73fviP7yN6RTfaO7NMK4r1H9ha0aRzfmLQGaaQ3Tmf6mul0eq4T13a4lod7P0yHhA7l9tnl3BA1NxPJd/k0n9SctIZpvH/T+2F/fxER8P5mImbWjcAe4MuCr/8XwDn3p5B2k4C5wD3A3af2JJvZYKA7cAj4sSx7knUzEYmEg0cPsjhvMQs3L2Th5oV8mfslh48fBiCldgo9knuQGJfI6p2rydqexZYDWwqmrVmtJmkN0ji/wfmkNUgjrWHged3qdQva7Duyj4lfTuTPi/7MoWOHuCntJh685EFa12td7p9VvFNSnx01e5IXfL+ALQe2ML7feK+jiIhEUhKwpdDrXODiwg3MrDPQ1Dn3vpndU2h4HDCWwF7ou8shq0ix4qvF069FP/q16AfA8ZPHWbl9JQu+X8DCLQv5aMNH7P1pL+0T2tOrWa9/FcUN02has2mpV7CqfV5txvUZx6iLRzHh8wk8/dXTvJ79Or+84Jf8odcfaFa7WXl8TPGxqCmSX1n1CrFVYrm67dVeRxER8YyZVSJwOMUvixj9EPBn59yPpRUYZjYSGAmQnJwc3pAiRagSU4X0xumkN07nt91+i3OOfJdPTKWYs3rf+jXqM77/eH7b7bc8tvAxpiydwssrX2ZE5xH8rufvSKqZFKZPIOeaqLgE3JETR5i+ZjpD2g8htmqs13FERCIpD2ha6HWT4LBT4oHzgflmtgnoCsw2s3QCe5wfDw7/DfA7M7uzqJk456Y659Kdc+kJCQnh/xQipTCzsy6QC0uMS2TSwElsGLWB4Z2GM3XZVFo+1ZK7PrqLHYd2nPX7Hzp2iHyXH4akUl6iYk/ynHVz2H90v25DLSLRYAnQ2sxSCBTHNwAFF4Z3zu0H6p96bWbz+dcxyT0LDX+IwDHJz5RPbBF/aFKzCVOumsK93e9l3GfjmLx4Ms99/RyjLhrFPd3vOe24Zgic87Tr8C5yD+SSdyCPvIN5geenHoPDDhw9QL3q9ejXoh/9WwROWEyupV9h/CwqiuTMrEwaxjakb4u+XkcREYko59yJ4N7fjwhcAm6ac261mY0DljrnZnubUOTckFInhRcHvch93e/j4U8fZvzn4/nr0r8ytMNQDh47WFAI5x3I43j+8dOmrWSVaBTXiKSaSbRPaE+/Fv1oFNeInN05zN0wlzdWvwFA23ptCwrm3s17n/Gl7iQyKvzVLfb+tJfEJxO5I/0OJg2cFLb3FREpitdXt/CCrm4h0SB7RzYPzn+QuRvmkhiXSFLNJJLik2hSs8m/HoPDGsY1pHKlovdDOudYvXM1czfMZe53c5m/aT4/nfiJypUq07VJ10DR3KI/FyZdWOx7SPiU1GdX+CL5b8v+xoh3R7BkxBLSG0fVv1si4gEVySLycxw9cZQvtnzB3O8CRfPXP3yNw1GrWi0uTbmU/i36c1mry2hRp4XXUSukqL4EXGZWJm3qtaFLoy5eRxERERE5TbXK1eiT0oc+KX14tO+j7D68m3kb5zF3w1w+/u5jZubMBKB70+4M7zScoalDdRGCclKhr26xZf8W5m+az7C0YaVeL1FERETEa/Vq1GNo6lCev/p5No3exNo71zK+33h2Hd7FbbNvI/HJREbMHsGi3EX47WiAiqZCF8mvZb8GoKtaiIiIyDnHzGhTrw33dr+Xb379DQtvXch1Ha7j1exX6fZCN9KmpDHxy4nsPLTT66gVUpmKZDMbaGZrzWy9md1XxPi7zGyNma0ys3lm1qzQuFvMbF3w75Zwhi/NK6teoWuTrrSs27I8ZysiIiISVmZG9+TuTBs0ja1jtjL1qqnEVY1jzMdjSJqYxHXTr+PD9R9yMv+k11ErjFKLZDOLAf4CXA50AG40sw4hzZYD6c65jsBbwOPBaesCDxK4QP1FwINmVid88Yu3avsqsnZkcXPazeUxOxEREZFyUbNaTUZ0GcGi/15E9h3Z3HnRnczfNJ/LMy8nZXIKD3zyABv3bvQ65jmvLCfuXQSsd859B2BmrwODgDWnGjjnPinUfhFwqjK9DJjrnNsTnHYuMBB47eyjlyxzVSYxFsPQ1KGRnpWIiIiIJ1IbpDLxsok81u8xZq+dzQvLX+CPn/2RRz57hL4pfenfoj/1atSjbvW61KsefAy+Pq/yeV7H97WyFMlJwJZCr3MJ7BkuznDggxKmjfhN0PNdPq9mv8rAVgNJiNXtUkVERKRiqxpTlWs7XMu1Ha5ly/4tvLTiJV5c8SL3zfu3o2QL1KhSo6B4Di2kE+MSuT71ehrGNSzHT+EvYb0EnJndDKQDl/zM6UYCIwGSk8/+Fo2fff8ZuQdyebzf42f9XiIiIiLnkqa1mvKHS/7A73v9nsPHD7Pnpz3s/ml34PHw7tNfFxq+esfqgtcn8k8w9v/G8qsuv+Le7vfSOL6x1x+r3JWlSM4DmhZ63SQ47DRm1g+4H7jEOXe00LS9Q6adHzqtc24qMBUCF6UvQ6YSZa7KJK5qHIPaDTrbtxIRERE5J5kZsVVjia0aS9NaTUufIMg5x7e7v2X85+N55qtneHbpswzvNJyxPcaSXOvsd2aeK8pydYslQGszSzGzqsANwOzCDcysE/AccLVzbkehUR8BA8ysTvCEvQHBYRFz5MQRpq+ZTka7DGpUqRHJWYmIiIhUOGZG2/ptmTZoGuv+Zx23/MctPL/seVo91YqR746MmpMCSy2SnXMngDsJFLffAG8651ab2TgzuzrYbAIQB0w3sxVmNjs47R7gEQKF9hJg3KmT+CJlzro57D+6n5s76qoWIiIiImcjpU4Kz/3nc6wftZ4RnUfw95V/p/XTrbl11q2s273O63gRZX67W0t6erpbunTpGU8/5I0hfLHlC3LvyqVypQp/120R8Rkz+9o5l+51jvJ0tv22iJw78g7kMeGLCTz39XMcO3mMG8+/kft73k/7hPZeRzsjJfXZFeqOe3t/2sv7697nhvNvUIEsIiIiEmZJNZOYNHASG0dv5K6udzEzZyapf03lhrduIHtHttfxwqpCFclvrXmLYyeP6VALERERkQhKjEtkwoAJbBq9ibHdx/L+uvdJm5LGNW9ew5x1c1i+dTm5B3I5euJo6W/mUxVqd2tmViZt6rWhS6MuXkcRERERqfASYhP4U78/cU/3e5i0aBKTF09mxjczTmsTXzWehNgEEmokkBCbQP0a9QPPg69PPTaIbUByrWQqmT/24VaYInnz/s18+v2njOs9DjPzOo6IiIhI1KhbvS7j+ozj7l/czcptK9l5eCe7Du9i56Gd7Dwc/Du0k9wDuazYtoKdh3Zy9OS/72VOqJFAn5Q+9E3pS9+UvrSo08Kzuq7CFMmvZQXudH1T2k0eJxERERGJTjWr1aRns56ltnPO8eOxHwuK552Hd/LDwR9YuHkh8zbO483VbwLQrFazQMHcoi+XplxKYlxipD9CgQpTJGdmZdKtSTda1m3pdRQRERERKYGZEV8tnvhq8bSo06Jg+MguI3HOsXb3WuZ9N495G+cxI2cG01ZMAyA1IbWgaL6k2SXUOq9WxDJWiCJ51fZVZO3I4pnLn/E6ioiIiIicBTOjXf12tKvfjl9f9GtO5p9k+bblBUXz88ue56mvniLGYkhvnF5QNPdq1iusVzerEEXyG9lvULlSZYamDvU6ioiIiIiEUUylQDGc3jidsT3GcvTEUb7M/ZJ/bvwn8zbOY/zn45m8eDJ7xob3fnUVokh+4JIHuKL1FSTEJngdRUREREQiqFrlavRu3pvezXszrs84Dh49yJqda6gaUzWs8/HHNTbOUrXK1eie3N3rGCIiIiJSzuKrxXNxk4vD/r4VokgWEREREQknFckiIiIiIiFUJIuIiIiIhFCRLCIiIiISQkWyiIiIiEgIFckiIiIiIiFUJIuIiIiIhFCRLCIiIiISQkWyiIiIiEgIFckiIiIiIiHMOed1htOY2U7ge69zFFIf2OV1iBB+y6Q8pfNbJr/lAf9lOtM8zZxzCeEO42c+67f9th6B/zL5LQ/4L5PylM5vmcLeZ/uuSPYbM1vqnEv3OkdhfsukPKXzWya/5QH/ZfJbHikbP35vfsvktzzgv0zKUzq/ZYpEHh1uISIiIiISQkWyiIiIiEgIFcmlm+p1gCL4LZPylM5vmfyWB/yXyW95pGz8+L35LZPf8oD/MilP6fyWKex5dEyyiIiIiEgI7UkWEREREQmhIhkws6Zm9omZrTGz1WY2uog2vc1sv5mtCP49EOFMm8wsKzivpUWMNzN7yszWm9kqM+sc4TxtC332FWZ2wMx+E9ImosvIzKaZ2Q4zyy40rK6ZzTWzdcHHOsVMe0uwzTozuyXCmSaYWU7we5lpZrWLmbbE7ziMeR4ys7xC38sVxUw70MzWBtep+8KRp4RMbxTKs8nMVhQzbSSWUZHbu9frkpSdH/vs4Dx902/7oc8OzsNX/bb67DPOFJ19tnMu6v+ARkDn4PN44FugQ0ib3sB75ZhpE1C/hPFXAB8ABnQFFpdjthhgG4FrC5bbMgJ6AZ2B7ELDHgfuCz6/DxhfxHR1ge+Cj3WCz+tEMNMAoHLw+fiiMpXlOw5jnoeAu8vwnW4AWgBVgZWh20A4M4WMfxJ4oByXUZHbu9frkv7O/jsMaVOufXZwnr7st73qs4Pz8FW/rT77zDKFjI+aPlt7kgHn3Fbn3LLg84PAN0CSt6lKNQh42QUsAmqbWaNymndfYINzrlxvHuCc+wzYEzJ4EPD34PO/A4OLmPQyYK5zbo9zbi8wFxgYqUzOuY+dcyeCLxcBTcIxrzPNU0YXAeudc985544BrxNYthHNZGYGDAVeC8e8ypinuO3d03VJyu4c7bPBu37bkz4b/Ndvq88+u0zR1merSA5hZs2BTsDiIkZ3M7OVZvaBmaVGOIoDPjazr81sZBHjk4AthV7nUn7/SNxA8RtIeS4jgIbOua3B59uAhkW08XJZ3UZgz1FRSvuOw+nO4E+J04r5ScqrZdQT2O6cW1fM+Iguo5Dt3e/rkhTBR302+Lff9lOfDf7e1tRnlyyq+mwVyYWYWRzwNvAb59yBkNHLCPxU9R/A08A7EY7TwznXGbgc+LWZ9Yrw/MrEzKoCVwPTixhd3svoNC7w24pvLtdiZvcDJ4DMYpqU13c8BWgJXABsJfBTmV/cSMl7JCK2jEra3v22LknRfNZngw/7bT/32eCvbU19dplEVZ+tIjnIzKoQWPiZzrkZoeOdcweccz8Gn88BqphZ/Ujlcc7lBR93ADMJ/LRSWB7QtNDrJsFhkXY5sMw5tz10RHkvo6Dtp36uDD7uKKJNuS8rM/slcBUwLLjx/psyfMdh4Zzb7pw76ZzLB54vZj5eLKPKwBDgjeLaRGoZFbO9+3JdkqL5rc8OzseP/bbf+mzw4bamPrt00dhnq0im4BibF4BvnHMTi2mTGGyHmV1EYNntjlCeWDOLP/WcwEkF2SHNZgP/ZQFdgf2FfnaIpGL/F1mey6iQ2cCps1VvAWYV0eYjYICZ1Qn+bDUgOCwizGwgcC9wtXPucDFtyvIdhytP4WMeM4qZzxKgtZmlBPc83UBg2UZSPyDHOZdb1MhILaMStnffrUtSNL/12cF5+LXf9lufDT7b1tRnl1n09dkujGcgnqt/QA8Cu+lXASuCf1cAtwO3B9vcCawmcAbpIuAXEczTIjiflcF53h8cXjiPAX8hcHZrFpBeDssplkAHWqvQsHJbRgQ6+q3AcQLHFQ0H6gHzgHXA/wF1g23Tgb8VmvY2YH3w79YIZ1pP4BioU+vSs8G2jYE5JX3HEcrzj+A6sopAp9IoNE/w9RUEzhreEK48xWUKDn/p1LpTqG15LKPitndP1yX9heU79KTPDs7Pd/02HvfZwXn4qt8uJo/67FIyBYe/RJT12brjnoiIiIhICB1uISIiIiISQkWyiIiIiEgIFckiIiIiIiFUJIuIiIiIhFCRLCIiIiISQkWyiIiIiEgIFckiIiIiIiFUJIuIiIiIhPh/+fQ/d9+tSMEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best Accuracy Achieved by Model: {max(history.history['accuracy'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDcD1oIOxD_g",
        "outputId": "e3c52d83-2ec7-4d91-fc94-050e9d834610"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy Achieved by Model: 0.31683874130249023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probabilities = model.predict(X_test)"
      ],
      "metadata": {
        "id": "3DGefVfUymDA"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnEDJkqMymFQ",
        "outputId": "6ce82c88-29ba-47e9-d8b2-d3956031c869"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24348253, 0.28289288, 0.1974156 , 0.07767271, 0.09359638,\n",
              "        0.10493986],\n",
              "       [0.42548427, 0.19832939, 0.17534554, 0.06687133, 0.0673522 ,\n",
              "        0.06661738],\n",
              "       [0.19253345, 0.18087788, 0.11479597, 0.22133149, 0.10125295,\n",
              "        0.18920822],\n",
              "       ...,\n",
              "       [0.20789012, 0.16484736, 0.10860516, 0.22253948, 0.08948753,\n",
              "        0.20663036],\n",
              "       [0.15155563, 0.2964909 , 0.15513547, 0.11650542, 0.10126229,\n",
              "        0.17905031],\n",
              "       [0.06949627, 0.45593363, 0.10828914, 0.13908653, 0.09650256,\n",
              "        0.13069192]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "metadata": {
        "id": "PEwHj50aymKc"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(X_test[\"labels\"], pred_probabilities, target_names =[\"anger\", \"fear\", \"joy\", \"disgust\", \"sadness\", \"surprise\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "xCtVb1YCymMr",
        "outputId": "bb0ad2ae-652c-4b39-933c-f0723d2cb211"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-6eb2548a9c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"anger\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"joy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"disgust\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sadness\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"surprise\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZExkzUz5ymOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TkdhAM2kymRr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}